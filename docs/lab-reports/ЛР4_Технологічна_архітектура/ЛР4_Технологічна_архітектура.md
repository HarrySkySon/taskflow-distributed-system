<a name="xace8629cb459e97e813ff0b75e640fca0dd0613"></a>**КИЇВСЬКИЙ НАЦІОНАЛЬНИЙ УНІВЕРСИТЕТ\
БУДІВНИЦТВА ТА АРХІТЕКТУРИ**\
\
\
Кафедра інформаційних технологій\
\
\
\
\
\
**ЛАБОРАТОРНА РОБОТА 1**\
\
з дисципліни

\
**"Архітектура розподілених програмних систем"**\
\
на тему:\
\
**"** **Технологічна архітектура"**\
\
\

**\
\
\
\

**\
\


Виконав: студент групи ІПЗм(д)-25\
Постановський Ігор Анатолійович\
\
Перевірив: Мазуренко Р.В.

Київ – 2025
# **Звіт про виконання Лабораторної роботи №4**
**Дисципліна:** Архітектура розподілених програмних систем 
## <a name="мета-роботи"></a>**Мета роботи**
Вивчити та обрати технологічний стек для розробки розподіленої системи TaskFlow, обґрунтувати вибір технологій, створити діаграму розгортання (Deployment Diagram) та описати інфраструктуру для кожного мікросервісу.
## <a name="завдання"></a>**Завдання**
1. Обрати технологічний стек для кожного мікросервісу системи TaskFlow
1. Обґрунтувати вибір кожної технології з врахуванням вимог до системи
1. Створити діаграму розгортання (Deployment Diagram) в PlantUML
1. Описати інфраструктурні компоненти (БД, черги повідомлень, сховища)
1. Визначити DevOps інструменти та CI/CD pipeline
1. Описати налаштування середовища розробки та production
1. Відповісти на контрольні питання
## <a name="теоретичні-відомості"></a>**1. Теоретичні відомості**
### <a name="критерії-вибору-технологій"></a>**1.1 Критерії вибору технологій**
При виборі технологічного стеку для розподіленої системи необхідно враховувати:

1. **Продуктивність (Performance):**
   - Швидкість обробки запитів
   - Пропускна здатність (throughput)
   - Ефективність використання ресурсів
1. **Масштабованість (Scalability):**
   - Горизонтальне масштабування (scale out)
   - Вертикальне масштабування (scale up)
   - Можливість розподіленої обробки
1. **Надійність (Reliability):**
   - Fault tolerance
   - High availability
   - Data durability
1. **Зручність розробки (Developer Experience):**
   - Навчальна крива
   - Наявність бібліотек та фреймворків
   - Якість документації
   - Розмір спільноти
1. **Вартість (Cost):**
   - Ліцензування
   - Вартість хостингу
   - Вартість підтримки
1. **Сумісність (Compatibility):**
   - Інтеграція з іншими технологіями
   - Підтримка стандартів
   - Кросплатформність
### <a name="x2dd9eab396fc2c9b5e937dace5e8dfb6b489bae"></a>**1.2 Типові технологічні стеки для мікросервісів**
#### <a name="backend-technologies"></a>***Backend Technologies:***
- **Node.js + Express:** JavaScript/TypeScript, non-blocking I/O, велика екосистема
- **Python + FastAPI:** Швидка розробка, ML/AI інтеграція, async/await
- **Java + Spring Boot:** Enterprise-ready, висока продуктивність, строга типізація
- **Go:** Висока продуктивність, конкурентність, малий footprint
- **.NET Core:** Кросплатформний, високопродуктивний, TypeScript-like C#
#### <a name="databases"></a>***Databases:***
- **PostgreSQL:** Реляційна БД, ACID, JSON support, розширюваність
- **MongoDB:** NoSQL, document-based, гнучка схема
- **Redis:** In-memory key-value store, кешування, черги
- **Cassandra:** Розподілена NoSQL, висока доступність
#### <a name="message-brokers"></a>***Message Brokers:***
- **RabbitMQ:** AMQP, flexible routing, management UI
- **Apache Kafka:** High throughput, event streaming, distributed log
- **NATS:** Lightweight, cloud-native, high performance
#### <a name="api-protocols"></a>***API Protocols:***
- **REST:** HTTP-based, stateless, широка підтримка
- **gRPC:** HTTP/2, binary protocol, code generation
- **GraphQL:** Query language, flexible data fetching
## <a name="технологічний-стек-системи-taskflow"></a>**2. Технологічний стек системи TaskFlow**
### <a name="загальний-огляд"></a>**2.1 Загальний огляд**
┌─────────────────────────────────────────────────────────┐\
│                  Frontend Layer                          │\
├─────────────────────────────────────────────────────────┤\
│  React 18 + TypeScript + Redux Toolkit + TanStack Query │\
└─────────────────────────────────────────────────────────┘\
`                          `↓ HTTPS (REST API)\
┌─────────────────────────────────────────────────────────┐\
│                  API Gateway Layer                       │\
├─────────────────────────────────────────────────────────┤\
│      Node.js 20 + Express + TypeScript + JWT            │\
└─────────────────────────────────────────────────────────┘\
`                          `↓ HTTP (REST API)\
┌─────────────────────────────────────────────────────────┐\
│              Microservices Layer                         │\
├───────────────┬──────────────┬──────────────────────────┤\
│ Users Service │ Projects Srv │ Tasks Service            │\
│ Node.js +     │ Node.js +    │ Node.js + Express        │\
│ Express +     │ Express +    │ TypeScript + Prisma      │\
│ TypeScript    │ TypeScript   │ PostgreSQL               │\
├───────────────┼──────────────┼──────────────────────────┤\
│ Notifications │ Analytics    │                          │\
│ Service       │ Service      │                          │\
│ Node.js +     │ Python 3.12 +│                          │\
│ Express       │ FastAPI      │                          │\
└───────────────┴──────────────┴──────────────────────────┘\
`                `↓                           ↓\
`        `┌──────────────┐          ┌──────────────────┐\
`        `│  RabbitMQ    │          │   PostgreSQL     │\
`        `│  (AMQP)      │          │   (Databases)    │\
`        `└──────────────┘          └──────────────────┘

-----
### <a name="xa8255a2eb910516fc8c348d8a25620d8e4c033d"></a>**2.2 Детальний розбір технологій по компонентах**
#### <a name="api-gateway"></a>***2.2.1 API Gateway***

|Компонент|Технологія|Версія|Обґрунтування|
| :- | :- | :- | :- |
|Runtime|Node.js|20 LTS|Асинхронний I/O, висока продуктивність для проксі-запитів|
|Framework|Express.js|4\.18|Легковаговий, гнучкий routing, велика екосистема middleware|
|Language|TypeScript|5\.3|Статична типізація, покращена підтримка IDE, меньше помилок|
|HTTP Client|Axios|1\.6|Promise-based, interceptors, automatic transforms|
|Auth|jsonwebtoken|9\.0|JWT токени, industry standard|
|Rate Limiting|express-rate-limit|7\.1|Захист від DDoS, API throttling|
|CORS|cors|2\.8|Cross-origin resource sharing|
|Validation|Joi|17\.11|Schema validation для request/response|
|Logging|Winston|3\.11|Structured logging, multiple transports|
|Circuit Breaker|opossum|8\.1|Захист від каскадних відмов|

**Dockerfile для API Gateway:**

**FROM** node:20-alpine **AS** builder\
**WORKDIR** /app\
**COPY** package\*.json ./\
**RUN** npm ci --only=production\
**COPY** . .\
**RUN** npm run build\
\
**FROM** node:20-alpine\
**WORKDIR** /app\
**COPY** --from=builder /app/dist ./dist\
**COPY** --from=builder /app/node\_modules ./node\_modules\
**EXPOSE** 3000\
**CMD** ["node", "dist/index.js"]
#### <a name="users-service"></a>***2.2.2 Users Service***

|Компонент|Технологія|Версія|Обґрунтування|
| :- | :- | :- | :- |
|Runtime|Node.js|20 LTS|Асинхронність, швидка розробка|
|Framework|Express.js|4\.18|REST API, middleware підтримка|
|Language|TypeScript|5\.3|Type safety для бізнес-логіки|
|ORM|Prisma|5\.7|Type-safe database client, migrations, інтроспекція|
|Database|PostgreSQL|16|ACID, надійність, JSON support|
|Password Hashing|bcrypt|5\.1|Cryptographically secure, salt rounds|
|JWT|jsonwebtoken|9\.0|Токени доступу та refresh токени|
|Validation|Zod|3\.22|TypeScript-first validation|
|Email|Nodemailer|6\.9|Email sending через SMTP|
|Message Queue|amqplib|0\.10|RabbitMQ client для Node.js|

**Environment Variables (.env):**

\# Database\
DATABASE\_URL="postgresql://user:password@postgres-users:5432/users\_db?schema=public"\
\
\# JWT\
JWT\_ACCESS\_SECRET="your-access-secret-key-256-bit"\
JWT\_REFRESH\_SECRET="your-refresh-secret-key-256-bit"\
JWT\_ACCESS\_EXPIRATION="15m"\
JWT\_REFRESH\_EXPIRATION="7d"\
\
\# RabbitMQ\
RABBITMQ\_URL="amqp://guest:guest@rabbitmq:5672"\
\
\# Server\
PORT=4001\
NODE\_ENV="production"

**Prisma Schema:**

generator client {\
`  `provider = "prisma-client-js"\
}\
\
datasource db {\
`  `provider = "postgresql"\
`  `url      = env("DATABASE\_URL")\
}\
\
model User {\
`  `id            Int       @id @default(autoincrement())\
`  `email         String    @unique @db.VarChar(255)\
`  `passwordHash  String    @map("password\_hash") @db.VarChar(255)\
`  `firstName     String    @map("first\_name") @db.VarChar(100)\
`  `lastName      String    @map("last\_name") @db.VarChar(100)\
`  `avatarUrl     String?   @map("avatar\_url") @db.VarChar(500)\
`  `isActive      Boolean   @default(true) @map("is\_active")\
`  `isVerified    Boolean   @default(false) @map("is\_verified")\
`  `createdAt     DateTime  @default(now()) @map("created\_at")\
`  `updatedAt     DateTime  @updatedAt @map("updated\_at")\
\
`  `roles         Role[]\
`  `refreshTokens RefreshToken[]\
\
`  `@@map("users")\
}\
\
model Role {\
`  `id        Int      @id @default(autoincrement())\
`  `userId    Int      @map("user\_id")\
`  `roleName  String   @map("role\_name") @db.VarChar(50)\
`  `createdAt DateTime @default(now()) @map("created\_at")\
\
`  `user User @relation(fields: [userId], references: [id], onDelete: Cascade)\
\
`  `@@unique([userId, roleName])\
`  `@@map("roles")\
}\
\
model RefreshToken {\
`  `id        Int      @id @default(autoincrement())\
`  `userId    Int      @map("user\_id")\
`  `token     String   @unique @db.VarChar(500)\
`  `expiresAt DateTime @map("expires\_at")\
`  `createdAt DateTime @default(now()) @map("created\_at")\
\
`  `user User @relation(fields: [userId], references: [id], onDelete: Cascade)\
\
`  `@@map("refresh\_tokens")\
}
#### <a name="projects-service"></a>***2.2.3 Projects Service***

|Компонент|Технологія|Версія|Обґрунтування|
| :- | :- | :- | :- |
|Runtime|Node.js|20 LTS|Consistency з іншими сервісами|
|Framework|Express.js|4\.18|REST API|
|Language|TypeScript|5\.3|Type safety|
|ORM|Prisma|5\.7|Type-safe ORM|
|Database|PostgreSQL|16|Реляційні дані (проєкти, члени)|
|HTTP Client|Axios|1\.6|Міжсервісні виклики (Users Service)|
|Validation|Zod|3\.22|Request validation|
|Message Queue|amqplib|0\.10|Event publishing|
#### <a name="tasks-service"></a>***2.2.4 Tasks Service***

|Компонент|Технологія|Версія|Обґрунтування|
| :- | :- | :- | :- |
|Runtime|Node.js|20 LTS|Consistency з іншими сервісами|
|Framework|Express.js|4\.18|REST API|
|Language|TypeScript|5\.3|Type safety|
|ORM|Prisma|5\.7|Підтримка складних зв’язків (tasks, comments, attachments)|
|Database|PostgreSQL|16|Реляційні дані, transactions|
|File Upload|Multer|1\.4|Multipart/form-data parsing|
|File Storage|MinIO Client|7\.1|S3-compatible object storage|
|HTTP Client|Axios|1\.6|Виклики до Projects, Users Services|
|Message Queue|amqplib|0\.10|Event publishing|

**File Upload Configuration:**

**import** multer **from** 'multer';\
\
**const** storage = multer.memoryStorage();\
\
**const** upload = multer({\
`  `storage,\
`  `limits: {\
`    `fileSize: 10 \* 1024 \* 1024, *// 10 MB*\
`  `},\
`  `fileFilter: (req, file, cb) **=>** {\
`    `**const** allowedMimeTypes = [\
`      `'image/jpeg',\
`      `'image/png',\
`      `'image/gif',\
`      `'application/pdf',\
`      `'application/msword',\
`      `'application/vnd.openxmlformats-officedocument.wordprocessingml.document',\
`    `];\
\
`    `**if** (allowedMimeTypes.includes(file.mimetype)) {\
`      `cb(**null**, **true**);\
`    `} **else** {\
`      `cb(**new** Error('Invalid file type'));\
`    `}\
`  `},\
});\
\
**export** **default** upload;
#### <a name="notifications-service"></a>***2.2.5 Notifications Service***

|Компонент|Технологія|Версія|Обґрунтування|
| :- | :- | :- | :- |
|Runtime|Node.js|20 LTS|Асинхронна обробка подій|
|Framework|Express.js|4\.18|REST API для управління нотифікаціями|
|Language|TypeScript|5\.3|Type safety|
|ORM|Prisma|5\.7|ORM для збереження нотифікацій|
|Database|PostgreSQL|16|Збереження історії нотифікацій|
|Email|Nodemailer|6\.9|SMTP клієнт|
|Template Engine|Handlebars|4\.7|Email templates|
|Message Queue|amqplib|0\.10|RabbitMQ consumer|
|HTTP Client|Axios|1\.6|Отримання даних користувачів|

**Email Template Example (Handlebars):**

<!DOCTYPE html>\
**<html>**\
**<head>**\
`  `**<style>**\
`    `body { **font-family**: Arial, sans-serif; }\
.container { **max-width**: 600px; **margin**: 0 auto; **padding**: 20px; }\
.header { **background-color**: #4CAF50; **color**: white; **padding**: 10px; }\
.content { **padding**: 20px; }\
.button { **background-color**: #4CAF50; **color**: white; **padding**: 10px 20px; **text-decoration**: none; }\
`  `**</style>**\
**</head>**\
**<body>**\
`  `**<div** class="container"**>**\
`    `**<div** class="header"**>**\
`      `**<h1>**TaskFlow Notification**</h1>**\
`    `**</div>**\
`    `**<div** class="content"**>**\
`      `**<h2>**New Task Assigned**</h2>**\
`      `**<p>**Hello {{firstName}},**</p>**\
`      `**<p>**You have been assigned to a new task: **<strong>**{{taskTitle}}**</strong></p>**\
`      `**<p>**Project: {{projectName}}**</p>**\
`      `**<p>**Priority: {{priority}}**</p>**\
`      `**<p>**Deadline: {{deadline}}**</p>**\
`      `**<p>**\
`        `**<a** href="{{taskUrl}}" class="button"**>**View Task**</a>**\
`      `**</p>**\
`    `**</div>**\
`  `**</div>**\
**</body>**\
**</html>**
#### <a name="analytics-service"></a>***2.2.6 Analytics Service***

|Компонент|Технологія|Версія|Обґрунтування|
| :- | :- | :- | :- |
|Runtime|Python|3\.12|Екосистема для data science, аналітики, візуалізації|
|Framework|FastAPI|0\.108|Async, швидкий, auto-generated OpenAPI docs|
|ORM|SQLAlchemy|2\.0|Python ORM, підтримка async|
|Database|PostgreSQL|16|Аналітичні дані, time-series|
|Message Queue|aio-pika|9\.3|Async RabbitMQ client для Python|
|Data Analysis|Pandas|2\.1|DataFrame operations, data manipulation|
|Visualization|Matplotlib|3\.8|Графіки та charts|
|PDF Generation|ReportLab|4\.0|PDF звіти|
|Excel Export|OpenPyXL|3\.1|Excel файли|
|HTTP Client|httpx|0\.25|Async HTTP client для міжсервісних викликів|

**FastAPI Application Structure:**

**from** fastapi **import** FastAPI, Depends, HTTPException\
**from** sqlalchemy.ext.asyncio **import** AsyncSession\
**from** typing **import** List\
**import** pandas **as** pd\
\
app = FastAPI(\
`    `title="TaskFlow Analytics Service",\
`    `version="1.0.0",\
`    `description="Analytics and reporting service"\
)\
\
@app.get("/api/analytics/projects/{project\_id}/burndown")\
**async** **def** get\_burndown\_chart(\
`    `project\_id: int,\
`    `start\_date: str,\
`    `end\_date: str,\
`    `db: AsyncSession = Depends(get\_db)\
):\
`    `*"""Generate burndown chart data for a project"""*\
`    `*# Fetch task events from database*\
`    `events = **await** fetch\_task\_events(db, project\_id, start\_date, end\_date)\
\
`    `*# Use pandas for data manipulation*\
`    `df = pd.DataFrame(events)\
`    `df['date'] = pd.to\_datetime(df['timestamp']).dt.date\
\
`    `*# Calculate remaining work per day*\
`    `burndown\_data = calculate\_burndown(df)\
\
`    `**return** {\
`        `"project\_id": project\_id,\
`        `"ideal\_line": burndown\_data["ideal"],\
`        `"actual\_line": burndown\_data["actual"],\
`        `"labels": burndown\_data["dates"]\
`    `}\
\
@app.post("/api/analytics/reports/generate")\
**async** **def** generate\_report(\
`    `report\_request: ReportRequest,\
`    `db: AsyncSession = Depends(get\_db)\
):\
`    `*"""Generate PDF or Excel report"""*\
`    `data = **await** collect\_report\_data(db, report\_request)\
\
`    `**if** report\_request.format == "pdf":\
`        `file\_buffer = generate\_pdf\_report(data)\
`    `**elif** report\_request.format == "excel":\
`        `file\_buffer = generate\_excel\_report(data)\
`    `**else**:\
`        `**raise** HTTPException(400, "Unsupported format")\
\
`    `*# Upload to MinIO*\
`    `file\_url = **await** upload\_to\_storage(file\_buffer, report\_request)\
\
`    `**return** {"report\_url": file\_url}

**Обґрунтування вибору Python для Analytics:** - Pandas для ефективної обробки великих обсягів даних - Matplotlib/Seaborn для візуалізації - NumPy для математичних обчислень - Велика екосистема ML/AI бібліотек (для майбутнього розширення) - FastAPI забезпечує високу продуктивність (порівнянну з Node.js)
### <a name="інфраструктурні-компоненти"></a>**2.3 Інфраструктурні компоненти**
#### <a name="postgresql"></a>***2.3.1 PostgreSQL***
**Версія:** 16 (Alpine Linux image для production)

**Конфігурація:** - Окрема база даних для кожного сервісу (Database per Service pattern) - Connection pooling через PgBouncer - Replication: Primary-Replica для read scaling

**Databases:**

taskflow\_users\_db       (Users Service)\
taskflow\_projects\_db    (Projects Service)\
taskflow\_tasks\_db       (Tasks Service)\
taskflow\_notifications\_db (Notifications Service)\
taskflow\_analytics\_db   (Analytics Service)

**Docker Compose Configuration:**

services**:**\
`  `postgres-users**:**\
`    `image**:** postgres:16-alpine\
`    `environment**:**\
`      `POSTGRES\_DB**:** taskflow\_users\_db\
`      `POSTGRES\_USER**:** taskflow\_user\
`      `POSTGRES\_PASSWORD**:** ${POSTGRES\_PASSWORD}\
`    `volumes**:**\
`      `**-** postgres-users-data:/var/lib/postgresql/data\
`    `ports**:**\
`      `**-** "5432:5432"\
`    `healthcheck**:**\
`      `test**:** **[**"CMD-SHELL"**,** "pg\_isready -U taskflow\_user"**]**\
`      `interval**:** 10s\
`      `timeout**:** 5s\
`      `retries**:** 5\
\
`  `postgres-projects**:**\
`    `image**:** postgres:16-alpine\
`    `environment**:**\
`      `POSTGRES\_DB**:** taskflow\_projects\_db\
`      `POSTGRES\_USER**:** taskflow\_user\
`      `POSTGRES\_PASSWORD**:** ${POSTGRES\_PASSWORD}\
`    `volumes**:**\
`      `**-** postgres-projects-data:/var/lib/postgresql/data\
\
`  `*# Similar configurations for other databases...*\
\
volumes**:**\
`  `postgres-users-data**:**\
`  `postgres-projects-data**:**\
`  `postgres-tasks-data**:**\
`  `postgres-notifications-data**:**\
`  `postgres-analytics-data**:**

**Performance Tuning (postgresql.conf):**

*# Memory Settings*\
shared\_buffers = 256MB\
effective\_cache\_size = 1GB\
work\_mem = 16MB\
maintenance\_work\_mem = 64MB\
\
*# Connection Settings*\
max\_connections = 100\
\
*# Write-Ahead Log*\
wal\_buffers = 16MB\
checkpoint\_completion\_target = 0.9\
\
*# Query Planner*\
random\_page\_cost = 1.1  *# For SSD storage*
#### <a name="rabbitmq"></a>***2.3.2 RabbitMQ***
**Версія:** 3.12-management (з Management UI)

**Plugins:** - rabbitmq\_management (Management UI) - rabbitmq\_prometheus (Metrics export) - rabbitmq\_shovel (Message forwarding)

**Configuration:**

services**:**\
`  `rabbitmq**:**\
`    `image**:** rabbitmq:3.12-management-alpine\
`    `environment**:**\
`      `RABBITMQ\_DEFAULT\_USER**:** taskflow\
`      `RABBITMQ\_DEFAULT\_PASS**:** ${RABBITMQ\_PASSWORD}\
`      `RABBITMQ\_DEFAULT\_VHOST**:** /taskflow\
`    `ports**:**\
`      `**-** "5672:5672"    *# AMQP*\
`      `**-** "15672:15672"  *# Management UI*\
`    `volumes**:**\
`      `**-** rabbitmq-data:/var/lib/rabbitmq\
`      `**-** ./rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf\
`    `healthcheck**:**\
`      `test**:** **[**"CMD"**,** "rabbitmq-diagnostics"**,** "ping"**]**\
`      `interval**:** 30s\
`      `timeout**:** 10s\
`      `retries**:** 5\
\
volumes**:**\
`  `rabbitmq-data**:**

**Exchange and Queue Setup:**

*// Initialize RabbitMQ topology*\
**async** **function** setupRabbitMQ(channel) {\
`  `*// Declare main topic exchange*\
`  `**await** channel.assertExchange('taskflow.events', 'topic', {\
`    `durable: **true**\
`  `});\
\
`  `*// Declare Dead Letter Exchange*\
`  `**await** channel.assertExchange('taskflow.dlx', 'topic', {\
`    `durable: **true**\
`  `});\
\
`  `*// Queues for Notifications Service*\
`  `**await** channel.assertQueue('notifications.user.registered', {\
`    `durable: **true**,\
`    `deadLetterExchange: 'taskflow.dlx',\
`    `deadLetterRoutingKey: 'failed.notifications.user.registered'\
`  `});\
\
`  `**await** channel.bindQueue(\
`    `'notifications.user.registered',\
`    `'taskflow.events',\
`    `'user.registered'\
`  `);\
\
`  `*// Similar setup for other queues...*\
}
#### <a name="minio-s3-compatible-storage"></a>***2.3.3 MinIO (S3-Compatible Storage)***
**Версія:** RELEASE.2024-01-01 (latest stable)

**Використання:** - Завантаження аватарів користувачів - Прикріплення файлів до задач - Зберігання згенерованих звітів (PDF, Excel)

**Configuration:**

services**:**\
`  `minio**:**\
`    `image**:** minio/minio:latest\
`    `command**:** server /data --console-address ":9001"\
`    `environment**:**\
`      `MINIO\_ROOT\_USER**:** ${MINIO\_ROOT\_USER}\
`      `MINIO\_ROOT\_PASSWORD**:** ${MINIO\_ROOT\_PASSWORD}\
`    `ports**:**\
`      `**-** "9000:9000"  *# API*\
`      `**-** "9001:9001"  *# Console*\
`    `volumes**:**\
`      `**-** minio-data:/data\
`    `healthcheck**:**\
`      `test**:** **[**"CMD"**,** "curl"**,** "-f"**,** "http://localhost:9000/minio/health/live"**]**\
`      `interval**:** 30s\
`      `timeout**:** 20s\
`      `retries**:** 3\
\
volumes**:**\
`  `minio-data**:**

**Buckets:**

taskflow-avatars      (User profile pictures)\
taskflow-attachments  (Task file attachments)\
taskflow-reports      (Generated analytics reports)

**MinIO Client Usage (Tasks Service):**

**import** { Client } **from** 'minio';\
\
**const** minioClient = **new** Client({\
`  `endPoint: process.env.MINIO\_ENDPOINT || 'minio',\
`  `port: parseInt(process.env.MINIO\_PORT || '9000'),\
`  `useSSL: process.env.MINIO\_USE\_SSL === 'true',\
`  `accessKey: process.env.MINIO\_ACCESS\_KEY,\
`  `secretKey: process.env.MINIO\_SECRET\_KEY,\
});\
\
*// Upload file*\
**async** **function** uploadAttachment(file: Express.Multer.File, taskId: number) {\
`  `**const** bucketName = 'taskflow-attachments';\
`  `**const** fileName = `task-${taskId}/${Date.now()}-${file.originalname}`;\
\
`  `**await** minioClient.putObject(\
`    `bucketName,\
`    `fileName,\
`    `file.buffer,\
`    `file.size,\
`    `{\
`      `'Content-Type': file.mimetype,\
`      `'X-Task-ID': taskId.toString(),\
`    `}\
`  `);\
\
`  `*// Generate presigned URL (valid for 7 days)*\
`  `**const** url = **await** minioClient.presignedGetObject(bucketName, fileName, 7 \* 24 \* 60 \* 60);\
\
`  `**return** {\
`    `fileName: file.originalname,\
`    `fileSize: file.size,\
`    `fileUrl: url,\
`    `storagePath: fileName,\
`  `};\
}
#### <a name="redis-caching-and-session-storage"></a>***2.3.4 Redis (Caching and Session Storage)***
**Версія:** 7.2-alpine

**Використання:** - Кешування часто запитуваних даних (user profiles, project info) - Session storage для JWT refresh tokens - Rate limiting counters - Idempotency keys для event processing

**Configuration:**

services**:**\
`  `redis**:**\
`    `image**:** redis:7.2-alpine\
`    `command**:** redis-server --appendonly yes --requirepass ${REDIS\_PASSWORD}\
`    `ports**:**\
`      `**-** "6379:6379"\
`    `volumes**:**\
`      `**-** redis-data:/data\
`    `healthcheck**:**\
`      `test**:** **[**"CMD"**,** "redis-cli"**,** "ping"**]**\
`      `interval**:** 10s\
`      `timeout**:** 5s\
`      `retries**:** 5\
\
volumes**:**\
`  `redis-data**:**

**Redis Client (Node.js):**

**import** { createClient } **from** 'redis';\
\
**const** redisClient = createClient({\
`  `url: `redis://:${process.env.REDIS\_PASSWORD}@redis:6379`,\
});\
\
**await** redisClient.connect();\
\
*// Caching example*\
**async** **function** getUserFromCache(userId: number) {\
`  `**const** cacheKey = `user:${userId}`;\
`  `**const** cached = **await** redisClient.get(cacheKey);\
\
`  `**if** (cached) {\
`    `**return** JSON.parse(cached);\
`  `}\
\
`  `*// Fetch from database*\
`  `**const** user = **await** prisma.user.findUnique({ where: { id: userId } });\
\
`  `*// Cache for 1 hour*\
`  `**await** redisClient.setEx(cacheKey, 3600, JSON.stringify(user));\
\
`  `**return** user;\
}\
\
*// Idempotency example*\
**async** **function** processEventIdempotent(event: Event) {\
`  `**const** idempotencyKey = `event:${event.type}:${event.id}`;\
`  `**const** exists = **await** redisClient.get(idempotencyKey);\
\
`  `**if** (exists) {\
`    `console.log('Event already processed');\
`    `**return**;\
`  `}\
\
`  `*// Process event*\
`  `**await** handleEvent(event);\
\
`  `*// Mark as processed (TTL 24 hours)*\
`  `**await** redisClient.setEx(idempotencyKey, 86400, 'processed');\
}
### <a name="моніторинг-та-логування"></a>**2.4 Моніторинг та Логування**
#### <a name="prometheus-grafana"></a>***2.4.1 Prometheus + Grafana***
**Prometheus (Metrics Collection):**

services**:**\
`  `prometheus**:**\
`    `image**:** prom/prometheus:latest\
`    `volumes**:**\
`      `**-** ./prometheus.yml:/etc/prometheus/prometheus.yml\
`      `**-** prometheus-data:/prometheus\
`    `ports**:**\
`      `**-** "9090:9090"\
`    `command**:**\
`      `**-** '--config.file=/etc/prometheus/prometheus.yml'\
`      `**-** '--storage.tsdb.path=/prometheus'\
\
volumes**:**\
`  `prometheus-data**:**

**prometheus.yml:**

global**:**\
`  `scrape\_interval**:** 15s\
`  `evaluation\_interval**:** 15s\
\
scrape\_configs**:**\
`  `**-** job\_name**:** 'api-gateway'\
`    `static\_configs**:**\
`      `**-** targets**:** **[**'api-gateway:3000'**]**\
\
`  `**-** job\_name**:** 'users-service'\
`    `static\_configs**:**\
`      `**-** targets**:** **[**'users-service:4001'**]**\
\
`  `**-** job\_name**:** 'projects-service'\
`    `static\_configs**:**\
`      `**-** targets**:** **[**'projects-service:4002'**]**\
\
`  `**-** job\_name**:** 'tasks-service'\
`    `static\_configs**:**\
`      `**-** targets**:** **[**'tasks-service:4003'**]**\
\
`  `**-** job\_name**:** 'notifications-service'\
`    `static\_configs**:**\
`      `**-** targets**:** **[**'notifications-service:4004'**]**\
\
`  `**-** job\_name**:** 'analytics-service'\
`    `static\_configs**:**\
`      `**-** targets**:** **[**'analytics-service:4005'**]**\
\
`  `**-** job\_name**:** 'rabbitmq'\
`    `static\_configs**:**\
`      `**-** targets**:** **[**'rabbitmq:15692'**]**\
\
`  `**-** job\_name**:** 'postgres'\
`    `static\_configs**:**\
`      `**-** targets**:** **[**'postgres-exporter:9187'**]**

**Grafana (Visualization):**

services**:**\
`  `grafana**:**\
`    `image**:** grafana/grafana:latest\
`    `environment**:**\
`      `GF\_SECURITY\_ADMIN\_PASSWORD**:** ${GRAFANA\_PASSWORD}\
`      `GF\_INSTALL\_PLUGINS**:** grafana-piechart-panel\
`    `ports**:**\
`      `**-** "3001:3000"\
`    `volumes**:**\
`      `**-** grafana-data:/var/lib/grafana\
`      `**-** ./grafana/dashboards:/etc/grafana/provisioning/dashboards\
`      `**-** ./grafana/datasources:/etc/grafana/provisioning/datasources\
\
volumes**:**\
`  `grafana-data**:**

**Metrics Instrumentation (Express.js):**

**import** promClient **from** 'prom-client';\
\
*// Create a Registry*\
**const** register = **new** promClient.Registry();\
\
*// Default metrics (CPU, memory, etc.)*\
promClient.collectDefaultMetrics({ register });\
\
*// Custom metrics*\
**const** httpRequestDuration = **new** promClient.Histogram({\
`  `name: 'http\_request\_duration\_seconds',\
`  `help: 'Duration of HTTP requests in seconds',\
`  `labelNames: ['method', 'route', 'status\_code'],\
`  `buckets: [0.1, 0.5, 1, 2, 5],\
});\
\
register.registerMetric(httpRequestDuration);\
\
*// Middleware*\
app.use((req, res, next) **=>** {\
`  `**const** start = Date.now();\
\
`  `res.on('finish', () **=>** {\
`    `**const** duration = (Date.now() - start) / 1000;\
`    `httpRequestDuration\
.labels(req.method, req.route?.path || req.path, res.statusCode.toString())\
.observe(duration);\
`  `});\
\
`  `next();\
});\
\
*// Metrics endpoint*\
app.get('/metrics', **async** (req, res) **=>** {\
`  `res.set('Content-Type', register.contentType);\
`  `res.end(**await** register.metrics());\
});
#### <a name="elk-stack-logging"></a>***2.4.2 ELK Stack (Logging)***
**Elasticsearch:**

services**:**\
`  `elasticsearch**:**\
`    `image**:** docker.elastic.co/elasticsearch/elasticsearch:8.11.0\
`    `environment**:**\
`      `**-** discovery.type=single-node\
`      `**-** xpack.security.enabled=false\
`      `**-** "ES\_JAVA\_OPTS=-Xms512m -Xmx512m"\
`    `ports**:**\
`      `**-** "9200:9200"\
`    `volumes**:**\
`      `**-** elasticsearch-data:/usr/share/elasticsearch/data\
\
volumes**:**\
`  `elasticsearch-data**:**

**Logstash:**

services**:**\
`  `logstash**:**\
`    `image**:** docker.elastic.co/logstash/logstash:8.11.0\
`    `volumes**:**\
`      `**-** ./logstash/pipeline:/usr/share/logstash/pipeline\
`    `ports**:**\
`      `**-** "5044:5044"  *# Beats input*\
`      `**-** "9600:9600"  *# Monitoring API*\
`    `depends\_on**:**\
`      `**-** elasticsearch

**logstash.conf:**

input **{**\
`  `beats **{**\
`    `port =**>** 5044\
`  `**}**\
**}**\
\
filter **{**\
`  `json **{**\
`    `source =**>** "message"\
`  `**}**\
\
`  `mutate **{**\
`    `add\_field =**>** **{** "index\_date" =**>** "%{+YYYY.MM.dd}" **}**\
`  `**}**\
**}**\
\
output **{**\
`  `elasticsearch **{**\
`    `hosts =**>** **["**elasticsearch:9200"**]**\
`    `index =**>** "taskflow-logs-%{index\_date}"\
`  `**}**\
\
`  `stdout **{** codec =**>** rubydebug **}**\
**}**

**Kibana:**

services**:**\
`  `kibana**:**\
`    `image**:** docker.elastic.co/kibana/kibana:8.11.0\
`    `environment**:**\
`      `ELASTICSEARCH\_HOSTS**:** http://elasticsearch:9200\
`    `ports**:**\
`      `**-** "5601:5601"\
`    `depends\_on**:**\
`      `**-** elasticsearch

**Structured Logging (Winston):**

**import** winston **from** 'winston';\
\
**const** logger = winston.createLogger({\
`  `level: 'info',\
`  `format: winston.format.combine(\
`    `winston.format.timestamp(),\
`    `winston.format.errors({ stack: **true** }),\
`    `winston.format.json()\
`  `),\
`  `defaultMeta: { service: 'users-service' },\
`  `transports: [\
`    `**new** winston.transports.File({ filename: 'error.log', level: 'error' }),\
`    `**new** winston.transports.File({ filename: 'combined.log' }),\
`    `**new** winston.transports.Console({\
`      `format: winston.format.combine(\
`        `winston.format.colorize(),\
`        `winston.format.simple()\
`      `),\
`    `}),\
`  `],\
});\
\
*// Usage*\
logger.info('User registered', {\
`  `userId: user.id,\
`  `email: user.email,\
`  `timestamp: **new** Date().toISOString(),\
});\
\
logger.error('Failed to send email', {\
`  `error: error.message,\
`  `stack: error.stack,\
`  `userId: user.id,\
});
### <a name="security-technologies"></a>**2.5 Security Technologies**
#### <a name="httpstls"></a>***2.5.1 HTTPS/TLS***
**Let’s Encrypt (Production):** - Автоматичні SSL сертифікати - Auto-renewal через Certbot - Nginx як reverse proxy

**Nginx Configuration:**

server {\
`    `listen 80;\
`    `server\_name taskflow.example.com;\
`    `return 301 https://$server\_name$request\_uri;\
}\
\
server {\
`    `listen 443 ssl http2;\
`    `server\_name taskflow.example.com;\
\
`    `ssl\_certificate /etc/letsencrypt/live/taskflow.example.com/fullchain.pem;\
`    `ssl\_certificate\_key /etc/letsencrypt/live/taskflow.example.com/privkey.pem;\
\
`    `ssl\_protocols TLSv1.2 TLSv1.3;\
`    `ssl\_ciphers HIGH:!aNULL:!MD5;\
`    `ssl\_prefer\_server\_ciphers on;\
\
`    `location /api/ {\
`        `proxy\_pass http://api-gateway:3000/;\
`        `proxy\_set\_header Host $host;\
`        `proxy\_set\_header X-Real-IP $remote\_addr;\
`        `proxy\_set\_header X-Forwarded-For $proxy\_add\_x\_forwarded\_for;\
`        `proxy\_set\_header X-Forwarded-Proto $scheme;\
`    `}\
}
#### <a name="secrets-management"></a>***2.5.2 Secrets Management***
**Docker Secrets (Docker Swarm):**

version**:** '3.8'\
\
services**:**\
`  `users-service**:**\
`    `image**:** taskflow/users-service\
`    `secrets**:**\
`      `**-** db\_password\
`      `**-** jwt\_secret\
`    `environment**:**\
`      `DATABASE\_PASSWORD\_FILE**:** /run/secrets/db\_password\
`      `JWT\_SECRET\_FILE**:** /run/secrets/jwt\_secret\
\
secrets**:**\
`  `db\_password**:**\
`    `external**:** true\
`  `jwt\_secret**:**\
`    `external**:** true

**Alternatives:** - **HashiCorp Vault:** For production-grade secrets management - **AWS Secrets Manager:** For AWS deployments - **Azure Key Vault:** For Azure deployments
#### <a name="security-headers"></a>***2.5.3 Security Headers***
**Helmet.js (Express):**

**import** helmet **from** 'helmet';\
\
app.use(helmet());\
\
*// Custom configuration*\
app.use(helmet({\
`  `contentSecurityPolicy: {\
`    `directives: {\
`      `defaultSrc: ["'self'"],\
`      `styleSrc: ["'self'", "'unsafe-inline'"],\
`      `scriptSrc: ["'self'"],\
`      `imgSrc: ["'self'", "data:", "https://storage.taskflow.com"],\
`    `},\
`  `},\
`  `hsts: {\
`    `maxAge: 31536000,\
`    `includeSubDomains: **true**,\
`    `preload: **true**,\
`  `},\
}));
### <a name="devops-та-cicd"></a>**2.6 DevOps та CI/CD**
#### <a name="containerization"></a>***2.6.1 Containerization***
**Multi-stage Dockerfile (Example):**

*# Stage 1: Build*\
**FROM** node:20-alpine **AS** builder\
\
**WORKDIR** /app\
\
**COPY** package\*.json ./\
**RUN** npm ci --only=production\
\
**COPY** tsconfig.json ./\
**COPY** src ./src\
**RUN** npm run build\
\
*# Stage 2: Production*\
**FROM** node:20-alpine\
\
**WORKDIR** /app\
\
*# Create non-root user*\
**RUN** addgroup -g 1001 nodejs **&&** adduser -u 1001 -G nodejs -s /bin/sh -D nodejs\
\
*# Copy built files*\
**COPY** --from=builder --chown=nodejs:nodejs /app/dist ./dist\
**COPY** --from=builder --chown=nodejs:nodejs /app/node\_modules ./node\_modules\
**COPY** --chown=nodejs:nodejs package.json ./\
\
**USER** nodejs\
\
**EXPOSE** 4001\
\
**HEALTHCHECK** --interval=30s --timeout=3s --start-period=5s --retries=3 \\
`  `**CMD** node -e "require('http').get('http://localhost:4001/health', (r) => { process.exit(r.statusCode === 200 ? 0 : 1); });"\
\
**CMD** ["node", "dist/index.js"]
#### <a name="docker-compose-development"></a>***2.6.2 Docker Compose (Development)***
**docker-compose.yml:**

version**:** '3.8'\
\
services**:**\
`  `*# Infrastructure*\
`  `postgres-users**:**\
`    `image**:** postgres:16-alpine\
`    `environment**:**\
`      `POSTGRES\_DB**:** taskflow\_users\_db\
`      `POSTGRES\_USER**:** taskflow\_user\
`      `POSTGRES\_PASSWORD**:** dev\_password\
`    `volumes**:**\
`      `**-** postgres-users-data:/var/lib/postgresql/data\
`    `ports**:**\
`      `**-** "5432:5432"\
\
`  `rabbitmq**:**\
`    `image**:** rabbitmq:3.12-management-alpine\
`    `environment**:**\
`      `RABBITMQ\_DEFAULT\_USER**:** taskflow\
`      `RABBITMQ\_DEFAULT\_PASS**:** dev\_password\
`    `ports**:**\
`      `**-** "5672:5672"\
`      `**-** "15672:15672"\
\
`  `redis**:**\
`    `image**:** redis:7.2-alpine\
`    `command**:** redis-server --requirepass dev\_password\
`    `ports**:**\
`      `**-** "6379:6379"\
\
`  `minio**:**\
`    `image**:** minio/minio:latest\
`    `command**:** server /data --console-address ":9001"\
`    `environment**:**\
`      `MINIO\_ROOT\_USER**:** minioadmin\
`      `MINIO\_ROOT\_PASSWORD**:** minioadmin\
`    `ports**:**\
`      `**-** "9000:9000"\
`      `**-** "9001:9001"\
\
`  `*# Microservices*\
`  `api-gateway**:**\
`    `build**:**\
`      `context**:** ./services/api-gateway\
`      `dockerfile**:** Dockerfile\
`    `environment**:**\
`      `PORT**:** 3000\
`      `NODE\_ENV**:** development\
`    `ports**:**\
`      `**-** "3000:3000"\
`    `depends\_on**:**\
`      `**-** users-service\
`      `**-** projects-service\
`      `**-** tasks-service\
\
`  `users-service**:**\
`    `build**:** ./services/users-service\
`    `environment**:**\
`      `DATABASE\_URL**:** postgresql://taskflow\_user:dev\_password@postgres-users:5432/taskflow\_users\_db\
`      `RABBITMQ\_URL**:** amqp://taskflow:dev\_password@rabbitmq:5672\
`      `REDIS\_URL**:** redis://:dev\_password@redis:6379\
`      `PORT**:** 4001\
`    `ports**:**\
`      `**-** "4001:4001"\
`    `depends\_on**:**\
`      `**-** postgres-users\
`      `**-** rabbitmq\
`      `**-** redis\
\
`  `*# ... other services*\
\
volumes**:**\
`  `postgres-users-data**:**\
`  `rabbitmq-data**:**\
`  `redis-data**:**\
`  `minio-data**:**
#### <a name="github-actions-cicd"></a>***2.6.3 GitHub Actions CI/CD***
**.github/workflows/ci.yml:**

name**:** CI/CD Pipeline\
\
on**:**\
`  `push**:**\
`    `branches**:** **[** main**,** develop **]**\
`  `pull\_request**:**\
`    `branches**:** **[** main **]**\
\
jobs**:**\
`  `test**:**\
`    `runs-on**:** ubuntu-latest\
`    `strategy**:**\
`      `matrix**:**\
`        `service**:** **[**api-gateway**,** users-service**,** projects-service**,** tasks-service**]**\
\
`    `steps**:**\
`      `**-** uses**:** actions/checkout@v4\
\
`      `**-** name**:** Setup Node.js\
`        `uses**:** actions/setup-node@v4\
`        `with**:**\
`          `node-version**:** '20'\
`          `cache**:** 'npm'\
`          `cache-dependency-path**:** services/${{ matrix.service }}/package-lock.json\
\
`      `**-** name**:** Install dependencies\
`        `working-directory**:** services/${{ matrix.service }}\
`        `run**:** npm ci\
\
`      `**-** name**:** Run linter\
`        `working-directory**:** services/${{ matrix.service }}\
`        `run**:** npm run lint\
\
`      `**-** name**:** Run tests\
`        `working-directory**:** services/${{ matrix.service }}\
`        `run**:** npm test\
\
`      `**-** name**:** Build\
`        `working-directory**:** services/${{ matrix.service }}\
`        `run**:** npm run build\
\
`  `build-and-push**:**\
`    `needs**:** test\
`    `runs-on**:** ubuntu-latest\
`    `if**:** github.ref == 'refs/heads/main'\
\
`    `steps**:**\
`      `**-** uses**:** actions/checkout@v4\
\
`      `**-** name**:** Login to Docker Hub\
`        `uses**:** docker/login-action@v3\
`        `with**:**\
`          `username**:** ${{ secrets.DOCKER\_USERNAME }}\
`          `password**:** ${{ secrets.DOCKER\_PASSWORD }}\
\
`      `**-** name**:** Build and push Docker images\
`        `run**:** |\
`          `docker build -t taskflow/api-gateway:latest ./services/api-gateway\
`          `docker push taskflow/api-gateway:latest\
\
`          `docker build -t taskflow/users-service:latest ./services/users-service\
`          `docker push taskflow/users-service:latest\
\
`          `# ... other services\
\
`  `deploy**:**\
`    `needs**:** build-and-push\
`    `runs-on**:** ubuntu-latest\
`    `if**:** github.ref == 'refs/heads/main'\
\
`    `steps**:**\
`      `**-** name**:** Deploy to production\
`        `uses**:** appleboy/ssh-action@v1.0.0\
`        `with**:**\
`          `host**:** ${{ secrets.PRODUCTION\_HOST }}\
`          `username**:** ${{ secrets.PRODUCTION\_USER }}\
`          `key**:** ${{ secrets.SSH\_PRIVATE\_KEY }}\
`          `script**:** |\
`            `cd /opt/taskflow\
`            `docker-compose pull\
`            `docker-compose up -d\
`            `docker system prune -af
#### <a name="kubernetes-production-orchestration"></a>***2.6.4 Kubernetes (Production Orchestration)***
**users-service-deployment.yaml:**

apiVersion**:** apps/v1\
kind**:** Deployment\
metadata**:**\
`  `name**:** users-service\
`  `namespace**:** taskflow\
spec**:**\
`  `replicas**:** 3\
`  `selector**:**\
`    `matchLabels**:**\
`      `app**:** users-service\
`  `template**:**\
`    `metadata**:**\
`      `labels**:**\
`        `app**:** users-service\
`    `spec**:**\
`      `containers**:**\
`      `**-** name**:** users-service\
`        `image**:** taskflow/users-service:latest\
`        `ports**:**\
`        `**-** containerPort**:** 4001\
`        `env**:**\
`        `**-** name**:** DATABASE\_URL\
`          `valueFrom**:**\
`            `secretKeyRef**:**\
`              `name**:** users-service-secrets\
`              `key**:** database-url\
`        `**-** name**:** JWT\_ACCESS\_SECRET\
`          `valueFrom**:**\
`            `secretKeyRef**:**\
`              `name**:** users-service-secrets\
`              `key**:** jwt-access-secret\
`        `resources**:**\
`          `requests**:**\
`            `memory**:** "256Mi"\
`            `cpu**:** "200m"\
`          `limits**:**\
`            `memory**:** "512Mi"\
`            `cpu**:** "500m"\
`        `livenessProbe**:**\
`          `httpGet**:**\
`            `path**:** /health\
`            `port**:** 4001\
`          `initialDelaySeconds**:** 30\
`          `periodSeconds**:** 10\
`        `readinessProbe**:**\
`          `httpGet**:**\
`            `path**:** /ready\
`            `port**:** 4001\
`          `initialDelaySeconds**:** 5\
`          `periodSeconds**:** 5\
\
\---\
apiVersion**:** v1\
kind**:** Service\
metadata**:**\
`  `name**:** users-service\
`  `namespace**:** taskflow\
spec**:**\
`  `selector**:**\
`    `app**:** users-service\
`  `ports**:**\
`  `**-** protocol**:** TCP\
`    `port**:** 4001\
`    `targetPort**:** 4001\
`  `type**:** ClusterIP\
\
\---\
apiVersion**:** autoscaling/v2\
kind**:** HorizontalPodAutoscaler\
metadata**:**\
`  `name**:** users-service-hpa\
`  `namespace**:** taskflow\
spec**:**\
`  `scaleTargetRef**:**\
`    `apiVersion**:** apps/v1\
`    `kind**:** Deployment\
`    `name**:** users-service\
`  `minReplicas**:** 3\
`  `maxReplicas**:** 10\
`  `metrics**:**\
`  `**-** type**:** Resource\
`    `resource**:**\
`      `name**:** cpu\
`      `target**:**\
`        `type**:** Utilization\
`        `averageUtilization**:** 70\
`  `**-** type**:** Resource\
`    `resource**:**\
`      `name**:** memory\
`      `target**:**\
`        `type**:** Utilization\
`        `averageUtilization**:** 80
## <a name="діаграма-розгортання-deployment-diagram"></a>**3. Діаграма розгортання (Deployment Diagram)**
Створено окремий файл: ЛР4\_Deployment\_Diagram.puml

![](Aspose.Words.6732a170-db44-48ce-b771-c82bb118a968.001.png)
## <a name="висновки"></a>**4. Висновки**
У ході виконання лабораторної роботи №4 було визначено та обґрунтовано технологічний стек для системи TaskFlow:
### <a name="основні-технологічні-рішення"></a>**4.1 Основні технологічні рішення**
1. **Backend:** Node.js 20 + Express + TypeScript для більшості сервісів
   - Асинхронний I/O для високої пропускної здатності
   - TypeScript для type safety та кращої підтримки IDE
   - Єдина мова для всіх сервісів (крім Analytics)
1. **Analytics Service:** Python 3.12 + FastAPI
   - Pandas/NumPy для ефективної обробки даних
   - Matplotlib для візуалізації
   - Велика екосистема data science бібліотек
1. **Databases:** PostgreSQL 16 (Database per Service)
   - ACID compliance для надійності
   - JSON support для гнучкості
   - Proven technology для production
1. **Message Broker:** RabbitMQ 3.12
   - Гнучкий routing через topic exchanges
   - Management UI для моніторингу
   - Dead Letter Queue для fault tolerance
1. **Caching:** Redis 7.2
   - In-memory storage для швидкого доступу
   - Idempotency keys
   - Rate limiting counters
1. **File Storage:** MinIO (S3-compatible)
   - Self-hosted alternative до AWS S3
   - Presigned URLs для безпечного доступу
   - Scalable object storage
1. **Monitoring:** Prometheus + Grafana
   - Metrics collection та alerting
   - Real-time dashboards
   - Industry standard tools
1. **Logging:** ELK Stack (Elasticsearch, Logstash, Kibana)
   - Centralized logging
   - Full-text search
   - Log analysis та visualization
1. **Orchestration:** Kubernetes
   - Auto-scaling (HPA)
   - Self-healing
   - Rolling updates та rollbacks
### <a name="переваги-обраного-стеку"></a>**4.2 Переваги обраного стеку**
- **Консистентність:** Node.js для більшості сервісів
- **Type Safety:** TypeScript у всіх Node.js сервісах
- **Продуктивність:** FastAPI (Python) майже так само швидкий як Node.js
- **Екосистема:** Велика кількість бібліотек та інструментів
- **Community Support:** Активні спільноти для всіх технологій
- **Production-Ready:** Всі технології proven у production середовищах
### <a name="масштабованість"></a>**4.3 Масштабованість**
- Horizontal scaling через Kubernetes HPA
- Database connection pooling (PgBouncer)
- Redis caching для зменшення навантаження на БД
- RabbitMQ для асинхронної обробки
- MinIO distributed mode для file storage scaling
## <a name="відповіді-на-контрольні-питання"></a>**5. Відповіді на контрольні питання**
### <a name="xe2a458b72226a5f00eb1ab14b1b417d7080beba"></a>**Питання 1: Які фактори впливають на вибір технологічного стеку?**
**Відповідь:**

При виборі технологічного стеку необхідно враховувати наступні фактори:

1. **Функціональні вимоги:**
   - Тип додатку (web, mobile, desktop, IoT)
   - Необхідні функції (real-time, batch processing, ML/AI)
   - Інтеграції з іншими системами
1. **Нефункціональні вимоги:**
   - **Продуктивність:** Latency, throughput, resource utilization
   - **Масштабованість:** Horizontal vs vertical scaling
   - **Надійність:** Uptime requirements, fault tolerance
   - **Безпека:** Authentication, encryption, compliance
1. **Технічні фактори:**
   - **Екосистема:** Наявність бібліотек, фреймворків, інструментів
   - **Community:** Розмір спільноти, активність розробки
   - **Документація:** Якість та повнота документації
   - **Backward compatibility:** Стабільність API
1. **Команда:**
   - **Експертиза:** Знання та досвід команди
   - **Навчальна крива:** Час на вивчення нових технологій
   - **Hiring:** Доступність розробників на ринку
1. **Бізнес-фактори:**
   - **Time to market:** Швидкість розробки MVP
   - **Вартість:** Ліцензування, hosting, підтримка
   - **Vendor lock-in:** Залежність від постачальника
   - **Довгострокова підтримка:** LTS versions, roadmap
1. **Operational factors:**
   - **DevOps:** CI/CD, monitoring, logging
   - **Deployment:** Containerization, orchestration
   - **Maintenance:** Updates, patches, migrations

**Приклад для TaskFlow:** - Вибрано Node.js через асинхронність (good для I/O-intensive operations) - Python для Analytics через pandas/matplotlib екосистему - PostgreSQL через ACID та proven reliability - Kubernetes для production orchestration та auto-scaling
### <a name="x4e4a521b76fe2b67cd2b87bbb6630bc652796be"></a>**Питання 2: Чому обрано PostgreSQL замість NoSQL (MongoDB)?**
**Відповідь:**

**Обґрунтування вибору PostgreSQL:**

1. **Реляційна структура даних:**
   - Проєкти, задачі, користувачі мають чіткі зв’язки (foreign keys)
   - One-to-many, many-to-many relationships (projects-members, tasks-comments)
   - Потрібна referential integrity (CASCADE DELETE)
1. **ACID Transactions:**
   - Критично для фінансових операцій (якщо буде billing)
   - Atomic operations (створення проєкту + додавання членів = одна транзакція)
   - Consistency guarantees
1. **Complex Queries:**
   - JOIN операції для аналітики (tasks JOIN projects JOIN users)
   - Aggregations (COUNT, SUM, AVG для звітів)
   - Window functions для burndown charts
1. **Data Integrity:**
   - Foreign key constraints
   - UNIQUE constraints (email)
   - CHECK constraints (priority in [‘low’, ‘medium’, ‘high’])
1. **JSON Support:**
   - PostgreSQL має JSONB type для гнучких полів
   - Indexes на JSON полях
   - Best of both worlds (relational + document)

**Коли MongoDB був би кращим:** - Якщо схема даних часто змінюється (flexible schema) - Якщо потрібен horizontal sharding out-of-the-box - Якщо переважно document-based операції без JOIN’ів - Якщо eventual consistency прийнятна

**Висновок для TaskFlow:** PostgreSQL обрано через: - Складні зв’язки між entities - Потреба в транзакціях - SQL expertise в команді - Proven reliability для production
### <a name="x10f0db8d7d67fe682f02735a2b3ef720cf66c62"></a>**Питання 3: Які переваги дає використання Docker та Kubernetes?**
**Відповідь:**

**Docker (Containerization):**

**Переваги:**

1. **Consistency (Консистентність):**
   - “Works on my machine” problem вирішена
   - Однакове середовище: dev, staging, production
   - Всі залежності упаковані в image
1. **Isolation (Ізоляція):**
   - Кожен сервіс в окремому контейнері
   - Не конфліктують версії (Node.js 18 vs Node.js 20)
   - Resource limits (CPU, memory)
1. **Portability (Переносимість):**
   - Run anywhere: local, cloud, on-premise
   - Cloud-agnostic (AWS, Azure, GCP)
   - Easy migration between environments
1. **Efficiency (Ефективність):**
   - Lightweight (share OS kernel)
   - Fast startup (seconds vs minutes для VM)
   - Більше containers на одному host
1. **Version Control:**
   - Image tags для versioning (v1.0.0, v1.1.0)
   - Rollback до попередньої версії
   - Immutable infrastructure

**Kubernetes (Orchestration):**

**Переваги:**

1. **Auto-Scaling:**
   - Horizontal Pod Autoscaler (HPA) based on CPU/memory
   - Scale up при високому навантаженні
   - Scale down для економії ресурсів

apiVersion**:** autoscaling/v2\
kind**:** HorizontalPodAutoscaler\
metadata**:**\
`  `name**:** users-service-hpa\
spec**:**\
`  `minReplicas**:** 3\
`  `maxReplicas**:** 10\
`  `metrics**:**\
`  `**-** type**:** Resource\
`    `resource**:**\
`      `name**:** cpu\
`      `target**:**\
`        `averageUtilization**:** 70

2. **Self-Healing:**
   - Automatic restart failed containers
   - Replace unresponsive pods
   - Health checks (liveness, readiness probes)
2. **Load Balancing:**
   - Automatic traffic distribution
   - Service discovery
   - Internal DNS
2. **Rolling Updates:**
   - Zero-downtime deployments
   - Gradual rollout (10% → 50% → 100%)
   - Automatic rollback при помилках

spec**:**\
`  `strategy**:**\
`    `type**:** RollingUpdate\
`    `rollingUpdate**:**\
`      `maxSurge**:** 1\
`      `maxUnavailable**:** 0

5. **Service Discovery:**
   - Automatic DNS для services
   - Environment variables injection
   - ConfigMaps та Secrets management
5. **Resource Management:**
   - Resource requests та limits
   - Quality of Service (QoS) classes
   - Node affinity/anti-affinity

**Приклад для TaskFlow:**

**Without Kubernetes:** - Manual scaling: SSH до серверів, run docker-compose up –scale - Manual recovery: Моніторити crashes, manually restart - Manual updates: Stop services, pull new images, restart

**With Kubernetes:** - Auto-scaling based on metrics - Automatic recovery при crashes - Rolling updates з одної команди: kubectl apply -f deployment.yaml
### <a name="x8927d7bc3d56a8d9457a8efba6d22a4a19806b2"></a>**Питання 4: Що таке CI/CD і які інструменти використовуються?**
**Відповідь:**

**CI/CD (Continuous Integration / Continuous Deployment):**

**Continuous Integration (CI):** - Автоматичне тестування коду при кожному commit - Автоматична збірка (build) додатку - Linting та code quality checks - Security scanning

**Continuous Deployment (CD):** - Автоматичне розгортання на staging/production - Automated testing на staging - Automatic rollback при помилках

**GitHub Actions Pipeline для TaskFlow:**

name**:** CI/CD Pipeline\
\
on**:**\
`  `push**:**\
`    `branches**:** **[** main**,** develop **]**\
`  `pull\_request**:**\
`    `branches**:** **[** main **]**\
\
jobs**:**\
`  `*# 1. Code Quality*\
`  `lint**:**\
`    `runs-on**:** ubuntu-latest\
`    `steps**:**\
`      `**-** uses**:** actions/checkout@v4\
`      `**-** uses**:** actions/setup-node@v4\
`      `**-** run**:** npm ci\
`      `**-** run**:** npm run lint      *# ESLint*\
`      `**-** run**:** npm run format    *# Prettier check*\
\
`  `*# 2. Security Scanning*\
`  `security**:**\
`    `runs-on**:** ubuntu-latest\
`    `steps**:**\
`      `**-** uses**:** actions/checkout@v4\
`      `**-** uses**:** snyk/actions/node@master  *# Vulnerability scanning*\
`        `env**:**\
`          `SNYK\_TOKEN**:** ${{ secrets.SNYK\_TOKEN }}\
\
`  `*# 3. Unit Tests*\
`  `test**:**\
`    `runs-on**:** ubuntu-latest\
`    `steps**:**\
`      `**-** uses**:** actions/checkout@v4\
`      `**-** uses**:** actions/setup-node@v4\
`      `**-** run**:** npm ci\
`      `**-** run**:** npm test          *# Jest unit tests*\
`      `**-** run**:** npm run test:coverage\
\
`  `*# 4. Build Docker Images*\
`  `build**:**\
`    `needs**:** **[**lint**,** security**,** test**]**\
`    `runs-on**:** ubuntu-latest\
`    `steps**:**\
`      `**-** uses**:** actions/checkout@v4\
`      `**-** uses**:** docker/login-action@v3\
`      `**-** uses**:** docker/build-push-action@v5\
`        `with**:**\
`          `push**:** true\
`          `tags**:** taskflow/users-service:${{ github.sha }}\
\
`  `*# 5. Deploy to Staging*\
`  `deploy-staging**:**\
`    `needs**:** build\
`    `if**:** github.ref == 'refs/heads/develop'\
`    `runs-on**:** ubuntu-latest\
`    `steps**:**\
`      `**-** name**:** Deploy to Staging\
`        `run**:** |\
`          `kubectl set image deployment/users-service \\
`            `users-service=taskflow/users-service:${{ github.sha }} \\
`            `--namespace=staging\
\
`  `*# 6. Integration Tests on Staging*\
`  `integration-tests**:**\
`    `needs**:** deploy-staging\
`    `runs-on**:** ubuntu-latest\
`    `steps**:**\
`      `**-** run**:** npm run test:integration\
\
`  `*# 7. Deploy to Production*\
`  `deploy-production**:**\
`    `needs**:** integration-tests\
`    `if**:** github.ref == 'refs/heads/main'\
`    `runs-on**:** ubuntu-latest\
`    `environment**:**\
`      `name**:** production\
`      `url**:** https://taskflow.example.com\
`    `steps**:**\
`      `**-** name**:** Deploy to Production\
`        `run**:** |\
`          `kubectl set image deployment/users-service \\
`            `users-service=taskflow/users-service:${{ github.sha }} \\
`            `--namespace=production

**Інструменти CI/CD:**

|Інструмент|Призначення|Переваги|
| :- | :- | :- |
|**GitHub Actions**|CI/CD platform|Інтеграція з GitHub, безкоштовно для public repos|
|**GitLab CI**|CI/CD platform|Built-in в GitLab, потужні pipelines|
|**Jenkins**|CI/CD server|Open-source, велика кількість plugins|
|**CircleCI**|CI/CD platform|Швидкі builds, Docker-first|
|**Travis CI**|CI/CD platform|Простота налаштування|
|**ArgoCD**|GitOps CD|Kubernetes-native, declarative deployments|

**Best Practices:**

1. **Automated Testing:**
   - Unit tests (80%+ coverage)
   - Integration tests
   - E2E tests на staging
1. **Environment Parity:**
   - Dev, staging, production ідентичні
   - Infrastructure as Code (Terraform, CloudFormation)
1. **Fail Fast:**
   - Stop pipeline on first failure
   - Quick feedback loop
1. **Security:**
   - Scan dependencies (Snyk, Dependabot)
   - Container scanning (Trivy, Clair)
   - Secrets management (GitHub Secrets, Vault)
1. **Monitoring:**
   - Monitor deployments
   - Automatic rollback on errors
   - Alerts на Slack/Email
### <a name="xe8f942756161c50bb9223811370a75479e5e43c"></a>**Питання 5: Як забезпечити high availability розподіленої системи?**
**Відповідь:**

**High Availability (HA)** означає, що система доступна 99.9%+ часу (максимум 8.76 годин downtime на рік).

**Стратегії для TaskFlow:**

**1. Redundancy (Надлишковість):**

**Application Layer:** - Мінімум 3 replicas кожного сервісу в Kubernetes - Load balancing між repliсами

spec**:**\
`  `replicas**:** 3\
`  `strategy**:**\
`    `type**:** RollingUpdate\
`    `rollingUpdate**:**\
`      `maxUnavailable**:** 1  *# Мінімум 2 pods завжди running*

**Database Layer:** - PostgreSQL Primary-Replica replication - Automatic failover (Patroni, Stolon) - Read replicas для розподілення read навантаження

**2. Health Checks:**

livenessProbe**:**\
`  `httpGet**:**\
`    `path**:** /health\
`    `port**:** 4001\
`  `initialDelaySeconds**:** 30\
`  `periodSeconds**:** 10\
`  `failureThreshold**:** 3\
\
readinessProbe**:**\
`  `httpGet**:**\
`    `path**:** /ready\
`    `port**:** 4001\
`  `initialDelaySeconds**:** 5\
`  `periodSeconds**:** 5

**3. Circuit Breaker:** - Захист від cascading failures - Automatic fallback при недоступності downstream service

**4. Message Queue Durability:** - Durable queues та exchanges в RabbitMQ - Message persistence на диск - Cluster mode (3+ nodes)

**5. Database Backups:** - Automated daily backups - Point-in-time recovery (PITR) - Replication to multiple availability zones

**6. Multi-Zone Deployment:**

apiVersion**:** v1\
kind**:** Pod\
spec**:**\
`  `affinity**:**\
`    `podAntiAffinity**:**\
`      `requiredDuringSchedulingIgnoredDuringExecution**:**\
`      `**-** labelSelector**:**\
`          `matchExpressions**:**\
`          `**-** key**:** app\
`            `operator**:** In\
`            `values**:**\
`            `**-** users-service\
`        `topologyKey**:** topology.kubernetes.io/zone

**7. Monitoring and Alerting:** - Prometheus metrics - Grafana dashboards - PagerDuty/Opsgenie для alerts

**8. Graceful Degradation:** - Критичні функції працюють навіть при падінні некритичних - Example: Users можуть працювати з tasks навіть якщо Analytics Service down

**Розрахунок Availability:**

Single instance availability: 99% (3.65 days downtime/year)\
\
With 3 replicas:\
Availability = 1 - (1 - 0.99)^3 = 1 - 0.000001 = 99.9999% (31.5 seconds downtime/year)

**Target SLA для TaskFlow:** - 99.9% availability (8.76 hours downtime/year) - Recovery Time Objective (RTO): < 5 minutes - Recovery Point Objective (RPO): < 15 minutes (max data loss)
##
## <a name="використані-матеріали"></a>**6. Використані матеріали**
1. **Офіційна документація:**
   - Docker Documentation
   - Kubernetes Documentation
   - PostgreSQL Documentation
   - RabbitMQ Documentation
   - Node.js Documentation
   - Python/FastAPI Documentation
1. **Книги:**
   - “Docker Deep Dive” - Nigel Poulton
   - “Kubernetes in Action” - Marko Lukša
   - “Designing Data-Intensive Applications” - Martin Kleppmann
1. **Online Resources:**
   - The Twelve-Factor App (https://12factor.net)
   - Awesome Docker (GitHub)
   - Kubernetes Best Practices

