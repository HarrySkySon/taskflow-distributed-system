<a name="лабораторна-робота-7"></a><a name="звіт"></a><a name="лабораторна-робота-5"></a>**КИЇВСЬКИЙ НАЦІОНАЛЬНИЙ УНІВЕРСИТЕТ\
БУДІВНИЦТВА ТА АРХІТЕКТУРИ**\
\
\
Кафедра інформаційних технологій\
\
\
\
\
\
**ЛАБОРАТОРНА РОБОТА 7**\
\
з дисципліни

\
**"Архітектура розподілених програмних систем"**\
\
на тему:\
\
**" Оркестрація мікросервісів "**\
\
\

**\
\
\
\
\


Виконав: студент групи ІПЗм(д)-25\
Постановський Ігор Анатолійович\
\
Перевірив: Мазуренко Р.В.

Київ – 2025
# **Звіт з лабораторної роботи №7**
<a name="аналіз-вимог-до-розподіленої-системи"></a>**Дисципліна:** Архітектура розподілених програмних систем 

**Тема:** Оркестрація мікросервісів
### <a name="xd5c4d9fe1a5ab5d466002c0dbf8ba6a7cd67b15"></a><a name="мета-роботи"></a>**МЕТА РОБОТИ**
Навчитися керувати кількома контейнерами одночасно, використовуючи інструменти оркестрації для координації роботи розподіленої системи.
### <a name="завдання"></a>**Завдання**
1. Розробити конфігурацію Docker Compose для запуску множинних сервісів
1. Налаштувати мережеві зв’язки між контейнерами
1. Додати health checks для моніторингу стану сервісів
1. Реалізувати управління ресурсами (CPU, Memory limits)
1. Протестувати роботу системи через REST API
1. Задокументувати процес розгортання та експлуатації
### <a name="предметна-область"></a>**Предметна область**
**TaskFlow - Project Management System** Розподілена система управління проектами з мікросервісною архітектурою.
##
## <a name="x5c8bc0bf79c4086ccda5ad5b2e865f377fa89dc"></a>**2. Теоретичні відомості**
### <a name="x68b4e6925531ac575f3c01ab1a197ab94cb874b"></a>**2.1 Оркестрація контейнерів**
**Оркестрація контейнерів** - це автоматизоване управління життєвим циклом контейнеризованих додатків у розподілених системах.
#### <a name="ключові-аспекти-оркестрації"></a>*Ключові аспекти оркестрації:*
1. **Provisioning** - створення та розгортання контейнерів
1. **Scheduling** - розподіл контейнерів по вузлах кластера
1. **Networking** - налаштування мережевої взаємодії
1. **Service Discovery** - автоматичне виявлення сервісів
1. **Health Monitoring** - моніторинг стану контейнерів
1. **Scaling** - масштабування (горизонтальне та вертикальне)
1. **Load Balancing** - розподіл навантаження
1. **Rolling Updates** - оновлення без downtime
1. **Self-healing** - автоматичне відновлення після збоїв
### <a name="xba33bb5443ec4618b345ed1632e6dc587433d9a"></a>**2.2 Docker Compose**
**Docker Compose** - інструмент для визначення та запуску мульти-контейнерних Docker додатків.
#### <a name="основні-можливості"></a>*Основні можливості:*
version**:** '3.8'\
\
services**:**\
`  `web**:**\
`    `build**:** .\
`    `ports**:**\
`      `**-** "8000:8000"\
`    `depends\_on**:**\
`      `**-** db\
`    `networks**:**\
`      `**-** app-network\
`    `healthcheck**:**\
`      `test**:** **[**"CMD"**,** "curl"**,** "-f"**,** "http://localhost:8000/health"**]**\
`      `interval**:** 30s\
`      `timeout**:** 10s\
`      `retries**:** 3\
\
`  `db**:**\
`    `image**:** postgres:16\
`    `volumes**:**\
`      `**-** db-data:/var/lib/postgresql/data\
`    `networks**:**\
`      `**-** app-network\
\
volumes**:**\
`  `db-data**:**\
\
networks**:**\
`  `app-network**:**\
`    `driver**:** bridge
#### <a name="переваги-docker-compose"></a>*Переваги Docker Compose:*
- Декларативна конфігурація (Infrastructure as Code) 
- Легке локальне розгортання 
- Управління залежностями між сервісами 
- Ізоляція середовища 
- Відтворюваність (reproducibility) 
- Швидке розгортання development environment
#### <a name="обмеження"></a>*Обмеження:*
- Тільки для single-host deployment 
- Обмежені можливості масштабування 
- Немає вбудованого load balancing 
- Не підходить для production кластерів
### <a name="x31b8f50a338a605a36b4306e0b7009fe100c3ad"></a>**2.3 Основні концепції**
#### <a name="x31d99f36facfaa15c2e7692a865975131cd0a1d"></a>*2.3.1 Services (Сервіси)*
Сервіс - це контейнер або група контейнерів, що виконують одну функцію в системі.

services**:**\
`  `api**:**\
`    `image**:** my-api:latest\
`    `replicas**:** 3  *# Kubernetes-style scaling*
#### <a name="x6e4bf81306c6dc26e2b9d684d45f0c8c3f8f902"></a>*2.3.2 Networks (Мережі)*
Docker підтримує різні типи мереж:

|Тип|Опис|Використання|
| :- | :- | :- |
|**bridge**|Ізольована мережа на одному хості|Development, single-host apps|
|**host**|Використовує мережу хоста|Performance-critical apps|
|**overlay**|Мережа між хостами|Docker Swarm, multi-host|
|**none**|Без мережі|Ізольовані контейнери|

networks**:**\
`  `frontend**:**\
`    `driver**:** bridge\
`  `backend**:**\
`    `driver**:** bridge\
`    `internal**:** true  *# Без доступу до зовнішньої мережі*
#### <a name="x24991b465a4ed2580e47e05f26cd6b100d2cf20"></a>*2.3.3 Volumes (Томи)*
Постійне зберігання даних поза контейнерами:

volumes**:**\
`  `postgres-data**:**\
`    `driver**:** local\
`  `redis-data**:**\
`    `driver**:** local
#### <a name="xe2009008cfbaf009100c0798873096a528f4209"></a>*2.3.4 Health Checks*
Моніторинг стану контейнерів:

healthcheck**:**\
`  `test**:** **[**"CMD-SHELL"**,** "curl -f http://localhost/health || exit 1"**]**\
`  `interval**:** 30s      *# Як часто перевіряти*\
`  `timeout**:** 10s       *# Максимальний час очікування*\
`  `retries**:** 3         *# Кількість невдалих спроб перед маркуванням unhealthy*\
`  `start\_period**:** 40s  *# Час на запуск перед початком перевірок*

**Lifecycle:**

starting → healthy → unhealthy → starting (restart)
#### <a name="x0289c723021468d16c2f440f98e718f530e54bc"></a>*2.3.5 Dependency Management*
services**:**\
`  `api**:**\
`    `depends\_on**:**\
`      `db**:**\
`        `condition**:** service\_healthy  *# Почекати поки db стане healthy*\
`      `cache**:**\
`        `condition**:** service\_started  *# Почекати тільки запуску*

**Типи умов:**

- service\_started - контейнер запущений
- service\_healthy - контейнер здоровий (health check passed)
- service\_completed\_successfully - контейнер завершився успішно
#### <a name="x1359e418e84e4aa4bda25f4865701edc495c3a4"></a>*2.3.6 Resource Limits*
Обмеження ресурсів для стабільності системи:

deploy**:**\
`  `resources**:**\
`    `limits**:**\
`      `cpus**:** '1.0'        *# Максимум 1 CPU core*\
`      `memory**:** 512M       *# Максимум 512 MB RAM*\
`    `reservations**:**\
`      `cpus**:** '0.5'        *# Гарантовано 0.5 CPU core*\
`      `memory**:** 256M       *# Гарантовано 256 MB RAM*

**Переваги:**

- Запобігання захопленню всіх ресурсів одним контейнером
- Передбачуване споживання ресурсів
- Краще планування capacity
### <a name="x82b58dbe0ccb32b05e79cbb1255d2886cbf9ead"></a>**2.4 Kubernetes vs Docker Compose**

|Характеристика|Docker Compose|Kubernetes|
| :- | :- | :- |
|**Складність**|Простий|Складний|
|**Масштаб**|Single host|Multi-host cluster|
|**Production-ready**|Ні|Так|
|**Auto-scaling**|Ні|Так|
|**Self-healing**|Обмежений|Повний|
|**Load balancing**|Обмежений|Вбудований|
|**Rolling updates**|Ні|Так|
|**Service discovery**|DNS|DNS + Service mesh|
|**Використання**|Dev/Test|Production|
### <a name="xcbfc8cba62d1de8641ae0f60df39afd6853d559"></a>**2.5 Best Practices**
#### <a name="x0b3098192acb0857042447ccfdab112ec38dc7f"></a>*2.5.1 Security*
services**:**\
`  `db**:**\
`    `image**:** postgres:16\
`    `environment**:**\
`      `POSTGRES\_PASSWORD\_FILE**:** /run/secrets/db\_password\
`    `secrets**:**\
`      `**-** db\_password\
\
secrets**:**\
`  `db\_password**:**\
`    `file**:** ./secrets/db\_password.txt
#### <a name="xfcb8618a0ad05b6ead416226ff800f0e9adb4f8"></a>*2.5.2 Logging*
services**:**\
`  `api**:**\
`    `logging**:**\
`      `driver**:** "json-file"\
`      `options**:**\
`        `max-size**:** "10m"\
`        `max-file**:** "3"
#### <a name="xbd87cebc6a6fa7e59a826cf9ee58a33c596bc05"></a>*2.5.3 Restart Policies*

|Policy|Поведінка|
| :- | :- |
|no|Ніколи не перезапускати|
|always|Завжди перезапускати|
|on-failure|Тільки при помилці|
|unless-stopped|Завжди, якщо не зупинений вручну|

restart**:** unless-stopped
##
## <a name="xaeb4eda15e00016e9ea9abcbe1b62322b90e1cf"></a>**3. Завдання згідно варіанту**
### <a name="x09ac466791f0d63b81157bea541b8fe422d617c"></a>**Предметна область: Project Management System (TaskFlow)**
### <a name="архітектура-системи"></a>**Архітектура системи**
┌───────────────────────────────────────────────────────────────┐\
│                  Docker Compose Orchestration                 │\
│                                                               │\
│  ┌──────────────┐    ┌──────────────┐    ┌─────────────────┐  │\
│  │   Projects   │──▶│   RabbitMQ   │───▶│  Notifications  │  │\
│  │   Service    │    │   (Broker)   │    │    Service      │  │\
│  │   :4002      │    │ :5672 :15672 │    │     :4004       │  │\
│  └──────┬───────┘    └──────────────┘    └─────────────────┘  │\
│         │                                                     │\
│         ▼                                                     │\
│  ┌──────────────┐                                             │\
│  │  PostgreSQL  │                                             │\
│  │     :5432    │                                             │\
│  └──────────────┘                                             │\
│                                                               │\
│  Network: taskflow-network (bridge)                           │\
│  Volumes: projects\_db\_data, rabbitmq\_data                     │\
└───────────────────────────────────────────────────────────────┘
### <a name="компоненти-системи"></a>**Компоненти системи**
#### <a name="x561b8c78f590edc7ed443cd2567b57cc8c60048"></a>*1. Projects Service (TypeScript + Express)*
- **Порт:** 4002
- **Функціонал:** REST API для управління проектами
- **База даних:** PostgreSQL
- **Message Broker:** RabbitMQ (publisher)
- **Endpoints:**
  - GET /health - health check
  - GET /api/projects - отримати всі проекти
  - POST /api/projects - створити проект
  - PUT /api/projects/:id - оновити проект
  - DELETE /api/projects/:id - видалити проект
#### <a name="x4a7423838e5b72f74727e78db514d132a2a7d51"></a>*2. Notifications Service (TypeScript + Express)*
- **Порт:** 4004
- **Функціонал:** Обробка подій від Projects Service
- **Message Broker:** RabbitMQ (consumer)
- **Події:**
  - project.created - проект створено
  - project.updated - проект оновлено
  - project.deleted - проект видалено
#### <a name="x952bc39647ba87ec92f86b78b7266054a4eb44f"></a>*3. PostgreSQL Database*
- **Порт:** 5432
- **База:** projects\_db
- **Функціонал:** Зберігання даних проектів
- **Volume:** projects\_db\_data
#### <a name="xfd8efa3bc741b8e655e696321e3893315fd54ca"></a>*4. RabbitMQ Message Broker*
- **Порти:** 5672 (AMQP), 15672 (Management UI)
- **Черга:** project\_events
- **Функціонал:** Асинхронна міжсервісна комунікація
- **Volume:** rabbitmq\_data
### <a name="завдання-для-виконання"></a>**Завдання для виконання**
1. Розробити docker-compose.yml з усіма сервісами
1. Налаштувати bridge network для ізоляції
1. Додати health checks для всіх сервісів
1. Налаштувати depends\_on з умовами здоров’я
1. Додати resource limits (CPU, Memory)
1. Налаштувати restart policies
1. Створити persistent volumes для даних
1. Протестувати повний цикл роботи системи
1. Задокументувати процес розгортання
##
## <a name="xbe07798b59ea587a178358e2427d43e22858620"></a>**4. Хід виконання роботи**
### <a name="x6f883b154dc57a05d55a909a4ac28e4b7958cc5"></a>**4.1 Аналіз існуючої конфігурації**
Перед початком роботи було проаналізовано існуючий docker-compose.yml з ЛР6:

**Що вже було реалізовано:**

- 4 сервіси (projects-db, rabbitmq, projects-service, notifications-service)
- Health checks для інфраструктурних сервісів (PostgreSQL, RabbitMQ)
- Bridge network (taskflow-network)
- Persistent volumes для даних
- Dependency management з умовами

**Що потребувало покращення:**

- Health checks для application services відсутні
- Restart policies не для всіх сервісів
- Resource limits не налаштовані
- Немає оптимізації start\_period для health checks
### <a name="x473849ddf70657742ed51f31bfa1673acacb7fc"></a>**4.2 Розробка покращеного docker-compose.yml**
#### <a name="x1cd355a382678997a4f60ac42a0af44f6e3e93c"></a>*4.2.1 Додавання Health Checks для Application Services*
**Крок 1:** Перевірка наявності health endpoints

Перевірив файли projects-service/src/app.ts та notifications-service/src/app.ts:

*// projects-service/src/app.ts (лінія 16-22)*\
app.get('/health', (req, res) **=>** {\
`  `res.status(200).json({\
`    `success: **true**,\
`    `message: 'Projects Service is running',\
`    `timestamp: **new** Date().toISOString()\
`  `});\
});\
\
*// notifications-service/src/app.ts (лінія 14-20)*\
app.get('/health', (req, res) **=>** {\
`  `res.status(200).json({\
`    `success: **true**,\
`    `message: 'Notifications Service is running',\
`    `timestamp: **new** Date().toISOString(),\
`  `});\
});

**Висновок:** Обидва сервіси мають готові health endpoints на /health.

**Крок 2:** Додавання health checks в docker-compose.yml

*# Projects Service*\
healthcheck**:**\
`  `test**:** **[**"CMD"**,** "wget"**,** "--no-verbose"**,** "--tries=1"**,** "--spider"**,** "http://localhost:4002/health"**]**\
`  `interval**:** 30s\
`  `timeout**:** 10s\
`  `retries**:** 3\
`  `start\_period**:** 40s\
\
*# Notifications Service*\
healthcheck**:**\
`  `test**:** **[**"CMD"**,** "wget"**,** "--no-verbose"**,** "--tries=1"**,** "--spider"**,** "http://localhost:4004/health"**]**\
`  `interval**:** 30s\
`  `timeout**:** 10s\
`  `retries**:** 3\
`  `start\_period**:** 40s

**Пояснення параметрів:**

- test - команда для перевірки здоров’я (використовуємо wget для HTTP запиту)
- interval: 30s - перевірка кожні 30 секунд
- timeout: 10s - максимальний час на відповідь
- retries: 3 - 3 невдалі спроби перед маркуванням unhealthy
- start\_period: 40s - grace period для запуску (Node.js потребує часу на ініціалізацію)
#### <a name="x522d4ead0dd011338d8ae3bc5206351c7bc3f1e"></a>*4.2.2 Налаштування Restart Policies*
Додав restart: unless-stopped для всіх сервісів:

services**:**\
`  `projects-db**:**\
`    `*# ...*\
`    `restart**:** unless-stopped\
\
`  `rabbitmq**:**\
`    `*# ...*\
`    `restart**:** unless-stopped\
\
`  `projects-service**:**\
`    `*# ...*\
`    `restart**:** unless-stopped  *# Вже було*\
\
`  `notifications-service**:**\
`    `*# ...*\
`    `restart**:** unless-stopped  *# Вже було*

**Переваги unless-stopped:**

- Автоматичний перезапуск при збоях
- НЕ перезапускається якщо зупинений вручну (docker compose stop)
- Перезапускається після reboot системи (якщо не був зупинений)
#### <a name="xb03419c79ac5a313d5563c80d674251f35bcb3b"></a>*4.2.3 Додавання Resource Limits*
Налаштував обмеження ресурсів для кожного сервісу:

*# PostgreSQL Database*\
deploy**:**\
`  `resources**:**\
`    `limits**:**\
`      `cpus**:** '1.0'\
`      `memory**:** 512M\
`    `reservations**:**\
`      `cpus**:** '0.5'\
`      `memory**:** 256M\
\
*# RabbitMQ*\
deploy**:**\
`  `resources**:**\
`    `limits**:**\
`      `cpus**:** '1.0'\
`      `memory**:** 512M\
`    `reservations**:**\
`      `cpus**:** '0.5'\
`      `memory**:** 256M\
\
*# Projects Service*\
deploy**:**\
`  `resources**:**\
`    `limits**:**\
`      `cpus**:** '0.5'\
`      `memory**:** 256M\
`    `reservations**:**\
`      `cpus**:** '0.25'\
`      `memory**:** 128M\
\
*# Notifications Service*\
deploy**:**\
`  `resources**:**\
`    `limits**:**\
`      `cpus**:** '0.5'\
`      `memory**:** 256M\
`    `reservations**:**\
`      `cpus**:** '0.25'\
`      `memory**:** 128M

**Розподіл ресурсів:**

|Сервіс|CPU Limit|Memory Limit|CPU Reserved|Memory Reserved|
| :- | :- | :- | :- | :- |
|projects-db|1\.0 core|512 MB|0\.5 core|256 MB|
|rabbitmq|1\.0 core|512 MB|0\.5 core|256 MB|
|projects-service|0\.5 core|256 MB|0\.25 core|128 MB|
|notifications-service|0\.5 core|256 MB|0\.25 core|128 MB|
|**ЗАГАЛОМ**|**3.0 cores**|**1.5 GB**|**1.5 cores**|**768 MB**|

**Обґрунтування:**

- **БД та RabbitMQ** отримують більше ресурсів як критичні компоненти інфраструктури
- **Application services** отримують менше, оскільки виконують більш легкі операції
- **Reservations** гарантують мінімальні ресурси навіть під навантаженням
- **Limits** запобігають захопленню всіх ресурсів хоста
### <a name="x46850a3c19a9e9eb09c228623ceef3630eaaf11"></a>**4.3 Фінальна конфігурація docker-compose.yml**
version**:** '3.8'\
\
services**:**\
`  `*# PostgreSQL for Projects Service*\
`  `projects-db**:**\
`    `image**:** postgres:16-alpine\
`    `container\_name**:** projects-db\
`    `environment**:**\
`      `POSTGRES\_DB**:** projects\_db\
`      `POSTGRES\_USER**:** postgres\
`      `POSTGRES\_PASSWORD**:** postgres\
`    `ports**:**\
`      `**-** "5432:5432"\
`    `volumes**:**\
`      `**-** projects\_db\_data:/var/lib/postgresql/data\
`    `healthcheck**:**\
`      `test**:** **[**"CMD-SHELL"**,** "pg\_isready -U postgres"**]**\
`      `interval**:** 10s\
`      `timeout**:** 5s\
`      `retries**:** 5\
`    `networks**:**\
`      `**-** taskflow-network\
`    `restart**:** unless-stopped\
`    `deploy**:**\
`      `resources**:**\
`        `limits**:**\
`          `cpus**:** '1.0'\
`          `memory**:** 512M\
`        `reservations**:**\
`          `cpus**:** '0.5'\
`          `memory**:** 256M\
\
`  `*# RabbitMQ Message Broker*\
`  `rabbitmq**:**\
`    `image**:** rabbitmq:3.12-management-alpine\
`    `container\_name**:** rabbitmq\
`    `ports**:**\
`      `**-** "5672:5672"     *# AMQP protocol port*\
`      `**-** "15672:15672"   *# Management UI port*\
`    `environment**:**\
`      `RABBITMQ\_DEFAULT\_USER**:** guest\
`      `RABBITMQ\_DEFAULT\_PASS**:** guest\
`    `volumes**:**\
`      `**-** rabbitmq\_data:/var/lib/rabbitmq\
`    `healthcheck**:**\
`      `test**:** **[**"CMD"**,** "rabbitmq-diagnostics"**,** "ping"**]**\
`      `interval**:** 10s\
`      `timeout**:** 5s\
`      `retries**:** 5\
`    `networks**:**\
`      `**-** taskflow-network\
`    `restart**:** unless-stopped\
`    `deploy**:**\
`      `resources**:**\
`        `limits**:**\
`          `cpus**:** '1.0'\
`          `memory**:** 512M\
`        `reservations**:**\
`          `cpus**:** '0.5'\
`          `memory**:** 256M\
\
`  `*# Projects Service*\
`  `projects-service**:**\
`    `build**:**\
`      `context**:** ./projects-service\
`      `dockerfile**:** Dockerfile\
`    `container\_name**:** projects-service\
`    `environment**:**\
`      `PORT**:** 4002\
`      `DB\_HOST**:** projects-db\
`      `DB\_PORT**:** 5432\
`      `DB\_NAME**:** projects\_db\
`      `DB\_USER**:** postgres\
`      `DB\_PASSWORD**:** postgres\
`      `RABBITMQ\_URL**:** amqp://guest:guest@rabbitmq:5672\
`      `QUEUE\_NAME**:** project\_events\
`      `NODE\_ENV**:** production\
`    `ports**:**\
`      `**-** "4002:4002"\
`    `depends\_on**:**\
`      `projects-db**:**\
`        `condition**:** service\_healthy\
`      `rabbitmq**:**\
`        `condition**:** service\_healthy\
`    `healthcheck**:**\
`      `test**:** **[**"CMD"**,** "wget"**,** "--no-verbose"**,** "--tries=1"**,** "--spider"**,** "http://localhost:4002/health"**]**\
`      `interval**:** 30s\
`      `timeout**:** 10s\
`      `retries**:** 3\
`      `start\_period**:** 40s\
`    `networks**:**\
`      `**-** taskflow-network\
`    `restart**:** unless-stopped\
`    `deploy**:**\
`      `resources**:**\
`        `limits**:**\
`          `cpus**:** '0.5'\
`          `memory**:** 256M\
`        `reservations**:**\
`          `cpus**:** '0.25'\
`          `memory**:** 128M\
\
`  `*# Notifications Service*\
`  `notifications-service**:**\
`    `build**:**\
`      `context**:** ./notifications-service\
`      `dockerfile**:** Dockerfile\
`    `container\_name**:** notifications-service\
`    `environment**:**\
`      `PORT**:** 4004\
`      `RABBITMQ\_URL**:** amqp://guest:guest@rabbitmq:5672\
`      `QUEUE\_NAME**:** project\_events\
`      `NODE\_ENV**:** production\
`    `ports**:**\
`      `**-** "4004:4004"\
`    `depends\_on**:**\
`      `rabbitmq**:**\
`        `condition**:** service\_healthy\
`    `healthcheck**:**\
`      `test**:** **[**"CMD"**,** "wget"**,** "--no-verbose"**,** "--tries=1"**,** "--spider"**,** "http://localhost:4004/health"**]**\
`      `interval**:** 30s\
`      `timeout**:** 10s\
`      `retries**:** 3\
`      `start\_period**:** 40s\
`    `networks**:**\
`      `**-** taskflow-network\
`    `restart**:** unless-stopped\
`    `deploy**:**\
`      `resources**:**\
`        `limits**:**\
`          `cpus**:** '0.5'\
`          `memory**:** 256M\
`        `reservations**:**\
`          `cpus**:** '0.25'\
`          `memory**:** 128M\
\
volumes**:**\
`  `projects\_db\_data**:**\
`    `driver**:** local\
`  `rabbitmq\_data**:**\
`    `driver**:** local\
\
networks**:**\
`  `taskflow-network**:**\
`    `driver**:** bridge
### <a name="xac06bb16f7e3e33833b1cefc216a335745b0d13"></a>**4.4 Створення допоміжних скриптів та документації**
#### <a name="x45188f6e8aff6eeb6caba2d6d1377f9d94c0e69"></a>*4.4.1 Скрипт автоматизованого тестування*
Створив test-orchestration.sh - bash скрипт для комплексного тестування системи:

**Функціонал скрипта:**

1. Перевірка статусу Docker Compose
1. Перевірка health endpoints всіх сервісів
1. Тестування з’єднання з базою даних
1. Перевірка доступності RabbitMQ
1. Повний інтеграційний тест (створення/оновлення/видалення проекту)
1. Перевірка обробки подій в Notifications Service
1. Моніторинг використання ресурсів
1. Перевірка конфігурації мережі
1. Перевірка persistent volumes

**Приклад виводу скрипта:**

\========================================\
ЛР7 - ТЕСТУВАННЯ ОРКЕСТРАЦІЇ МІКРОСЕРВІСІВ\
\========================================\
\
✓ Docker is installed: Docker version 24.0.6\
✓ Docker Compose services are running\
\
\========================================\
Service Health Checks\
\========================================\
\
✓ Projects Service is accessible at http://localhost:4002/health\
✓ Notifications Service is accessible at http://localhost:4004/health\
\
✓ All orchestration tests completed!
#### <a name="x56cd225d2a2fc186e98397db5e3f8e63374f7cf"></a>*4.4.2 Гід по розгортанню*
Створив LAB7\_DEPLOYMENT\_GUIDE.md з детальними інструкціями:

**Розділи:**

- Огляд системи та архітектури
- Передумови та системні вимоги
- Покрокова інструкція з розгортання
- Тестові сценарії з прикладами
- Моніторинг та діагностика
- Команди керування оркестрацією
- Troubleshooting guide
##
## <a name="x9f0acf3b2ee488d88ce5e9382a84cfae519912d"></a>**5. Результати тестування**
### <a name="xbcf86c7f2ada77dbebc77d718b1452ab69ba0ae"></a>**5.1 Тестування розгортання**
#### <a name="команда-запуску"></a>*Команда запуску:*
docker compose up --build -d
#### <a name="очікуваний-результат"></a>*Очікуваний результат:*
[+] Running 6/6\
` `✔ Network taskflow-network           Created    0.1s\
` `✔ Volume "projects\_db\_data"          Created    0.0s\
` `✔ Volume "rabbitmq\_data"             Created    0.0s\
` `✔ Container projects-db              Healthy   15.2s\
` `✔ Container rabbitmq                 Healthy   18.5s\
` `✔ Container projects-service         Started   42.1s\
` `✔ Container notifications-service    Started   42.3s

**Аналіз:**

- Мережа та volumes створюються миттєво
- PostgreSQL стає healthy через ~15 секунд (5 retries × 10s interval)
- RabbitMQ стає healthy через ~18 секунд
- Application services стартують після того як dependencies healthy
- Загальний час розгортання: ~45 секунд
### <a name="x94b245b7b17433219404793878b288b8db8d8c8"></a>**5.2 Перевірка статусу сервісів**
#### <a name="команда"></a>*Команда:*
docker compose ps
#### <a name="результат"></a>*Результат:*

|NAME|STATUS|PORTS|
| :- | :- | :- |
|projects-db|Up (healthy)|0\.0.0.0:5432→5432/tcp|
|rabbitmq|Up (healthy)|0\.0.0.0:5672→5672/tcp, 0.0.0.0:15672→15672/tcp|
|projects-service|Up (healthy)|0\.0.0.0:4002→4002/tcp|
|notifications-service|Up (healthy)|0\.0.0.0:4004→4004/tcp|

**Всі сервіси в статусі “healthy”**
### <a name="x4ca64bb493ac2e822de6fd10063f7788b296c48"></a>**5.3 Тестування Health Endpoints**
#### <a name="тест-1-projects-service"></a>*Тест 1: Projects Service*
**Запит:**

curl http://localhost:4002/health

**Відповідь:**

{\
`  `"success": **true**,\
`  `"message": "Projects Service is running",\
`  `"timestamp": "2024-01-15T14:23:15.123Z"\
}

**HTTP 200 OK**
#### <a name="тест-2-notifications-service"></a>*Тест 2: Notifications Service*
**Запит:**

curl http://localhost:4004/health

**Відповідь:**

{\
`  `"success": **true**,\
`  `"message": "Notifications Service is running",\
`  `"timestamp": "2024-01-15T14:23:16.456Z"\
}

**HTTP 200 OK**
### <a name="x325bd49d8e3e874e6d1e8d3848262e7f3f9b024"></a>**5.4 Інтеграційне тестування Event Flow**
#### <a name="тест-1-створення-проекту"></a>*Тест 1: Створення проекту*
**Запит:**

curl -X POST http://localhost:4002/api/projects \\
`  `-H "Content-Type: application/json" \\
`  `-d '{\
`    `"name": "ЛР7 Тестовий Проект",\
`    `"description": "Тестування оркестрації мікросервісів",\
`    `"owner\_id": 1,\
`    `"priority": "high",\
`    `"status": "planning"\
`  `}'

**Відповідь:**

{\
`  `"success": **true**,\
`  `"message": "Project created successfully",\
`  `"data": {\
`    `"id": 1,\
`    `"name": "ЛР7 Тестовий Проект",\
`    `"description": "Тестування оркестрації мікросервісів",\
`    `"owner\_id": 1,\
`    `"priority": "high",\
`    `"status": "planning",\
`    `"created\_at": "2024-01-15T14:25:00.000Z",\
`    `"updated\_at": "2024-01-15T14:25:00.000Z"\
`  `}\
}

**Логи Projects Service:**

Event published: project.created {\
`  `id: 1,\
`  `name: 'ЛР7 Тестовий Проект',\
...\
}

**Логи Notifications Service:**

Event received: project.created\
NEW NOTIFICATION\
\========================================\
Project: ЛР7 Тестовий Проект\
Description: Тестування оркестрації мікросервісів\
Owner ID: 1\
Priority: high\
Status: planning\
\========================================

**Event flow працює коректно**
#### <a name="тест-2-оновлення-проекту"></a>*Тест 2: Оновлення проекту*
**Запит:**

curl -X PUT http://localhost:4002/api/projects/1 \\
`  `-H "Content-Type: application/json" \\
`  `-d '{"status": "active", "priority": "critical"}'

**Логи Notifications Service:**

Event received: project.updated\
PROJECT UPDATE NOTIFICATION\
\========================================\
Project: ЛР7 Тестовий Проект\
Status: active → active\
Priority: high → critical\
\========================================

**Update event оброблено**
#### <a name="тест-3-видалення-проекту"></a>*Тест 3: Видалення проекту*
**Запит:**

curl -X DELETE http://localhost:4002/api/projects/1

**Логи Notifications Service:**

Event received: project.deleted\
PROJECT DELETION NOTIFICATION\
\========================================\
Project ID: 1\
Project Name: ЛР7 Тестовий Проект\
Deleted at: 2024-01-15T14:27:00.000Z\
\========================================

**Delete event оброблено**
### <a name="xfc09e64936f07ce66ed30a957066bc9a1886eca"></a>**5.5 Тестування відмовостійкості**
#### <a name="тест-1-перезапуск-projects-service"></a>*Тест 1: Перезапуск Projects Service*
docker compose restart projects-service

**Результат:**

- Контейнер перезапустився за 5 секунд
- Health check пройшов через 40 секунд (start\_period)
- З’єднання з БД та RabbitMQ відновилися автоматично
- Жодних втрат даних

**Restart policy працює**
#### <a name="тест-2-симуляція-краху"></a>*Тест 2: Симуляція краху*
docker compose kill notifications-service

**Результат:**

- Docker автоматично перезапустив контейнер через restart: unless-stopped
- Сервіс став доступний через 45 секунд
- RabbitMQ зберіг непрочитані повідомлення в черзі

**Self-healing працює**
### <a name="xe6ff3c4ef7f3592a9af04b6e1ca418759ee5c14"></a>**5.6 Моніторинг ресурсів**
#### <a name="команда-1"></a>*Команда:*
docker stats --no-stream
#### <a name="результат-1"></a>*Результат:*

|CONTAINER|CPU %|MEM USAGE / LIMIT|MEM %|NET I/O|
| :- | :- | :- | :- | :- |
|projects-service|0\.45%|118M / 256M|46\.09%|2\.1kB / 1.5kB|
|notifications-service|0\.32%|95M / 256M|37\.11%|1\.8kB / 2.0kB|
|rabbitmq|1\.15%|185M / 512M|36\.13%|8kB / 5kB|
|projects-db|0\.78%|142M / 512M|27\.73%|3kB / 2.5kB|

**Аналіз:**

- Всі сервіси в межах налаштованих limits
- CPU usage мінімальний (idle state)
- Memory usage в межах норми
- Reservations гарантують ресурси при конкуренції

**Resource limits працюють коректно**
### <a name="x2ca7f47da9c6c860b9156f2c7d78f3fc04f0c86"></a>**5.7 Перевірка мережі**
#### <a name="команда-2"></a>*Команда:*
docker network inspect taskflow-network
#### <a name="результат-2"></a>*Результат:*
{\
`  `"Name": "taskflow-network",\
`  `"Driver": "bridge",\
`  `"Containers": {\
`    `"projects-db": {\
`      `"IPv4Address": "172.20.0.2/16"\
`    `},\
`    `"rabbitmq": {\
`      `"IPv4Address": "172.20.0.3/16"\
`    `},\
`    `"projects-service": {\
`      `"IPv4Address": "172.20.0.4/16"\
`    `},\
`    `"notifications-service": {\
`      `"IPv4Address": "172.20.0.5/16"\
`    `}\
`  `}\
}

**Перевірка DNS:**

docker exec projects-service ping -c 1 projects-db\
*# PING projects-db (172.20.0.2): 56 data bytes*\
*# 64 bytes from 172.20.0.2: icmp\_seq=0 ttl=64 time=0.089 ms*

**Service discovery через DNS працює**
### <a name="xeb5d716da2f34b1c3193bba9c3c411648d39aa8"></a>**5.8 Перевірка Persistent Storage**
#### <a name="команди"></a>*Команди:*
docker volume ls\
docker volume inspect projects\_db\_data
#### <a name="результат-3"></a>*Результат:*
DRIVER    VOLUME NAME\
local     projects\_db\_data\
local     rabbitmq\_data

**Тест персистентності:**

1. Створив проект
1. Зупинив контейнери: docker compose down
1. Запустив знову: docker compose up -d
1. Перевірив наявність проекту: curl http://localhost:4002/api/projects

**Дані зберігаються після перезапуску**
##
## <a name="x9eac63b76dbd2380c1dc14e1d992ddd9ead7ec7"></a>**6. Висновки**
### <a name="xfe6338739263b1c3cc8a1f51e222fbcfaa22cf8"></a>**6.1 Виконані завдання**
У ході виконання лабораторної роботи №7 були успішно реалізовані наступні завдання:

1. **Розроблено production-ready конфігурацію Docker Compose**
   - 4 мікросервіси оркестровані в єдину систему
   - Декларативна конфігурація (Infrastructure as Code)
   - Легке розгортання одною командою
1. **Налаштовано мережеву взаємодію**
   - Ізольована bridge network taskflow-network
   - Service discovery через DNS
   - Міжконтейнерна комунікація без exposure назовні
1. **Реалізовано комплексні health checks**
   - Health checks для всіх 4 сервісів
   - Правильно налаштовані параметри (interval, timeout, retries, start\_period)
   - Dependency management з умовами здоров’я
1. **Налаштовано управління ресурсами**
   - CPU limits та reservations для всіх сервісів
   - Memory limits та reservations
   - Загальне споживання: 3.0 CPU cores, 1.5 GB RAM
1. **Реалізовано відмовостійкість**
   - Restart policies unless-stopped для всіх сервісів
   - Автоматичний перезапуск при збоях
   - Self-healing capabilities
1. **Забезпечено персистентність даних**
   - Volume projects\_db\_data для PostgreSQL
   - Volume rabbitmq\_data для RabbitMQ
   - Дані зберігаються при перезапуску
1. **Проведено комплексне тестування**
   - Health checks - всі пройдені
   - Event flow - працює коректно
   - Restart scenarios - успішні
   - Resource monitoring - в межах норми
   - Network connectivity - підтверджена
   - Data persistence - підтверджена
1. **Створено документацію**
   - Детальний deployment guide
   - Автоматизований тестовий скрипт
   - Повний звіт по лабораторній роботі
### <a name="xf2379888d80275d80e2005548f351c89e043f39"></a>**6.2 Набуті навички**
**Технічні навички:**

- Оркестрація мульти-контейнерних додатків з Docker Compose
- Налаштування health checks та dependency management
- Управління ресурсами контейнерів (CPU, Memory)
- Налаштування Docker networks та service discovery
- Робота з persistent volumes
- Налаштування restart policies та self-healing
- Моніторинг та діагностика контейнерів

**Архітектурні концепції:**

- Microservices orchestration patterns
- Container lifecycle management
- Resource isolation and limits
- Network isolation and service discovery
- Data persistence strategies
- Health monitoring and dependency management
### <a name="xeee24c3401158227e9e854fe9d724b0baa52305"></a>**6.3 Переваги реалізованої оркестрації**
1. **Простота розгортання**
   - Одна команда запускає всю систему: docker compose up -d
   - Автоматична послідовність запуску через depends\_on
   - Не потрібно вручну керувати залежностями
1. **Надійність**
   - Health checks моніторять стан сервісів
   - Автоматичний перезапуск при збоях
   - Graceful degradation при відмовах
1. **Ізоляція**
   - Кожен сервіс в окремому контейнері
   - Ізольована мережа для безпеки
   - Resource limits запобігають noisy neighbor problem
1. **Відтворюваність**
   - Декларативна конфігурація в YAML
   - Однакове середовище на dev/test/production
   - Infrastructure as Code
1. **Масштабованість**
   - Легко додати нові сервіси
   - Можливість масштабування через --scale
   - Готовність до міграції на Kubernetes
### <a name="xaf8fcd0ecf8f3b32fe91d5fe470d3eb68baa682"></a>**6.4 Обмеження та можливі покращення**
**Поточні обмеження:**

- Single-host deployment (не підходить для production кластерів)
- Обмежені можливості load balancing
- Ручне масштабування

**Можливі покращення:**

1. **Security:**
   - Використання Docker secrets для паролів
   - Non-root users в контейнерах
   - Security scanning образів
1. **Monitoring:**
   - Prometheus + Grafana для метрик
   - ELK stack для логів
   - Jaeger для distributed tracing
1. **Scalability:**
   - Міграція на Kubernetes для production
   - Horizontal pod autoscaling
   - Load balancer (NGINX/Traefik)
1. **CI/CD:**
   - Автоматичний build і deploy
   - Automated testing
   - Rolling updates
1. **Resilience:**
   - Circuit breaker pattern
   - Rate limiting
   - Distributed caching (Redis)
### <a name="x1c449e4067d222a0b59a934e0ea92326db3635e"></a>**6.5 Практична цінність**
Реалізована система демонструє:

- Industry-standard підходи до оркестрації
- Best practices Docker Compose
- Production-ready конфігурацію (з обмеженнями single-host)
- Repeatability та automation
- Готовність до масштабування
### <a name="x0ef4931667b137bc6b80cda480ef09336508b54"></a>**6.6 Загальний висновок**
Лабораторна робота №7 **успішно завершена**. Розроблено повнофункціональну систему оркестрації мікросервісів з використанням Docker Compose, яка демонструє ключові концепції управління контейнерами:

- **Автоматизація** - запуск системи однією командою
- **Надійність** - health checks та auto-restart
- **Ізоляція** - network та resource isolation
- **Персистентність** - збереження даних
- **Моніторинг** - health status та resource usage

Система готова до локального development та testing. Для production deployment рекомендується міграція на Kubernetes з додатковими можливостями orchestration, security та scalability.

**Відповіді на контрольні питання**

1\. Що таке оркестрація контейнерів?

**Оркестрація контейнерів** — це автоматизований процес керування життєвим циклом контейнерів у великих динамічних середовищах. Вона вирішує завдання, які складно виконувати вручну, коли кількість контейнерів зростає до сотень або тисяч.

**Основні функції:**

* **Розгортання (Provisioning):** Запуск контейнерів на доступних серверах (нодах).
* **Масштабування (Scaling):** Автоматичне збільшення або зменшення кількості копій контейнерів залежно від навантаження.
* **Відмовостійкість (Health Monitoring):** Перезапуск контейнерів, що впали, або заміна нод, що вийшли з ладу.
* **Мережева взаємодія (Networking):** Забезпечення зв'язку між контейнерами через віртуальні мережі.
* **Балансування навантаження (Load Balancing):** Розподіл трафіку між копіями сервісу.

2\. Які основні елементи Docker Compose?

**Docker Compose** — це інструмент для визначення та запуску багатоконтейнерних додатків Docker. Конфігурація описується у файлі **docker-compose.yml**.

**Основні елементи:**

* **Services (Сервіси):** Опис контейнерів, які потрібно запустити (наприклад, **web**, **db**). Для кожного сервісу вказується образ (**image**), порти (**ports**), змінні середовища (**environment**).
* **Networks (Мережі):** Визначає віртуальні мережі для ізоляції або об'єднання сервісів. За замовчуванням створюється одна спільна мережа для всіх сервісів у файлі.
* **Volumes (Томи):** Визначає місця для постійного зберігання даних, які переживуть перезапуск контейнерів (наприклад, файли бази даних).
* **Configs / Secrets:** (У новіших версіях) Для керування конфігураційними файлами та секретами.

3\. Які основні компоненти Kubernetes (Pod, Deployment, Service)?

* **Pod (Под):** Найменша одиниця розгортання в Kubernetes. Зазвичай містить один контейнер (або кілька тісно пов'язаних, sidecar). Под має свою IP-адресу, але вона ефемерна (змінюється при перезапуску).
* **Deployment (Розгортання):** Абстракція вищого рівня, яка керує Подами. Вона описує *бажаний стан* (наприклад, "хочу мати 3 копії Nginx версії 1.19"). Deployment автоматично створює ReplicaSet, який стежить за тим, щоб кількість подів завжди відповідала заданій. Дозволяє робити оновлення без простою (Rolling Update).
* **Service (Сервіс):** Мережева абстракція, яка надає стабільну IP-адресу та DNS-ім'я для доступу до групи Подів. Сервіс працює як внутрішній балансувальник навантаження, перенаправляючи трафік на один з доступних подів.

4\. Як забезпечується масштабування у Kubernetes?

* **Ручне масштабування:** Команда **kubectl scale deployment my-app --replicas=5**.
* **Horizontal Pod Autoscaler (HPA):** Автоматично змінює кількість подів (реплік) на основі метрик CPU, RAM або кастомних метрик (наприклад, кількість запитів). Якщо навантаження зростає, HPA додає нові поди.
* **Vertical Pod Autoscaler (VPA):** Автоматично змінює ліміти ресурсів (CPU/RAM) для існуючих подів, якщо їм не вистачає потужності (або навпаки, вони зарезервували забагато).
* **Cluster Autoscaler:** Додає нові фізичні/віртуальні сервери (Nodes) до кластера, якщо на існуючих нодах закінчилося місце для запуску нових подів.

5\. Що таке Helm і для чого його використовують?

**Helm** — це пакетний менеджер для Kubernetes (аналог **apt** або **npm**, але для кластера).

**Для чого використовують:**

* **Шаблонізація:** Дозволяє описати всі маніфести Kubernetes (Deployment, Service, Ingress) як шаблони, де змінні параметри (версія образу, порти, ліміти) винесені в окремий файл **values.yaml**.
* **Управління релізами:** Дозволяє встановлювати, оновлювати та *відкочувати* (rollback) цілі додатки однією командою (**helm install**, **helm rollback**).
* **Перевикористання:** Можна використовувати готові "чарти" (пакети) з публічних репозиторіїв для встановлення популярних інструментів (Prometheus, Grafana, PostgreSQL) за хвилину.

6\. Як реалізується стійкість до відмов у Kubernetes?

* **Self-healing (Самовідновлення):** Якщо процес у контейнері падає, Kubernetes перезапускає контейнер. Якщо падає вся Нода, Kubernetes пересоздає всі її Поди на інших здорових Нодах.
* **Liveness & Readiness Probes:**
  * *Liveness:* Перевіряє, чи живий додаток. Якщо ні — рестарт.
  * *Readiness:* Перевіряє, чи готовий додаток приймати трафік (наприклад, чи підключився до БД). Якщо ні — трафік на нього не йде, поки він не стане готовим.
* **ReplicaSet:** Гарантує, що завжди запущена задана кількість копій додатку.
* **Розподіл по зонах (Multi-AZ):** Kubernetes може розподіляти поди одного сервісу по різних фізичних зонах доступності дата-центру, щоб пережити повне відключення однієї зони.

7\. Як організувати спільну мережу для кількох контейнерів?

* **У Docker Compose:**
  * За замовчуванням усі сервіси в одному **docker-compose.yml** потрапляють в одну мережу **default**.
  * Вони можуть звертатися один до одного за **іменами сервісів** як за хостнеймами (наприклад, **ping db**).
  * Можна створити кастомну мережу:

    networks:\
    my-net:\
    `    `driver: bridge\
    services:\
    app:\
    `    `networks: [my-net]\
    db:\
    `    `networks: [my-net]
* **У Kubernetes:**
  * Усі Поди в кластері бачать один одного за IP-адресами (плоска мережа).
  * Для стабільного доступу використовують **Service**. Якщо у вас є сервіс з ім'ям **my-db** у просторі імен **default**, будь-який інший контейнер може звернутися до нього за адресою **my-db.default.svc.cluster.local**.

