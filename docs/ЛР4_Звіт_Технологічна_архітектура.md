# Лабораторна робота №4: Технологічна архітектура

**Дисципліна:** Архітектура розподілених програмних систем
**Студент:** [ПІБ]
**Група:** [Група]
**Дата виконання:** 18.12.2025

---

## Мета роботи

Вивчити та обрати технологічний стек для розробки розподіленої системи TaskFlow, обґрунтувати вибір технологій, створити діаграму розгортання (Deployment Diagram) та описати інфраструктуру для кожного мікросервісу.

---

## Завдання

1. Обрати технологічний стек для кожного мікросервісу системи TaskFlow
2. Обґрунтувати вибір кожної технології з врахуванням вимог до системи
3. Створити діаграму розгортання (Deployment Diagram) в PlantUML
4. Описати інфраструктурні компоненти (БД, черги повідомлень, сховища)
5. Визначити DevOps інструменти та CI/CD pipeline
6. Описати налаштування середовища розробки та production
7. Відповісти на контрольні питання

---

## 1. Теоретичні відомості

### 1.1 Критерії вибору технологій

При виборі технологічного стеку для розподіленої системи необхідно враховувати:

1. **Продуктивність (Performance):**
   - Швидкість обробки запитів
   - Пропускна здатність (throughput)
   - Ефективність використання ресурсів

2. **Масштабованість (Scalability):**
   - Горизонтальне масштабування (scale out)
   - Вертикальне масштабування (scale up)
   - Можливість розподіленої обробки

3. **Надійність (Reliability):**
   - Fault tolerance
   - High availability
   - Data durability

4. **Зручність розробки (Developer Experience):**
   - Навчальна крива
   - Наявність бібліотек та фреймворків
   - Якість документації
   - Розмір спільноти

5. **Вартість (Cost):**
   - Ліцензування
   - Вартість хостингу
   - Вартість підтримки

6. **Сумісність (Compatibility):**
   - Інтеграція з іншими технологіями
   - Підтримка стандартів
   - Кросплатформність

---

### 1.2 Типові технологічні стеки для мікросервісів

#### **Backend Technologies:**
- **Node.js + Express:** JavaScript/TypeScript, non-blocking I/O, велика екосистема
- **Python + FastAPI:** Швидка розробка, ML/AI інтеграція, async/await
- **Java + Spring Boot:** Enterprise-ready, висока продуктивність, строга типізація
- **Go:** Висока продуктивність, конкурентність, малий footprint
- **.NET Core:** Кросплатформний, високопродуктивний, TypeScript-like C#

#### **Databases:**
- **PostgreSQL:** Реляційна БД, ACID, JSON support, розширюваність
- **MongoDB:** NoSQL, document-based, гнучка схема
- **Redis:** In-memory key-value store, кешування, черги
- **Cassandra:** Розподілена NoSQL, висока доступність

#### **Message Brokers:**
- **RabbitMQ:** AMQP, flexible routing, management UI
- **Apache Kafka:** High throughput, event streaming, distributed log
- **NATS:** Lightweight, cloud-native, high performance

#### **API Protocols:**
- **REST:** HTTP-based, stateless, широка підтримка
- **gRPC:** HTTP/2, binary protocol, code generation
- **GraphQL:** Query language, flexible data fetching

---

## 2. Технологічний стек системи TaskFlow

### 2.1 Загальний огляд

```
┌─────────────────────────────────────────────────────────┐
│                  Frontend Layer                          │
├─────────────────────────────────────────────────────────┤
│  React 18 + TypeScript + Redux Toolkit + TanStack Query │
└─────────────────────────────────────────────────────────┘
                          ↓ HTTPS (REST API)
┌─────────────────────────────────────────────────────────┐
│                  API Gateway Layer                       │
├─────────────────────────────────────────────────────────┤
│      Node.js 20 + Express + TypeScript + JWT            │
└─────────────────────────────────────────────────────────┘
                          ↓ HTTP (REST API)
┌─────────────────────────────────────────────────────────┐
│              Microservices Layer                         │
├───────────────┬──────────────┬──────────────────────────┤
│ Users Service │ Projects Srv │ Tasks Service            │
│ Node.js +     │ Node.js +    │ Node.js + Express        │
│ Express +     │ Express +    │ TypeScript + Prisma      │
│ TypeScript    │ TypeScript   │ PostgreSQL               │
├───────────────┼──────────────┼──────────────────────────┤
│ Notifications │ Analytics    │                          │
│ Service       │ Service      │                          │
│ Node.js +     │ Python 3.12 +│                          │
│ Express       │ FastAPI      │                          │
└───────────────┴──────────────┴──────────────────────────┘
                ↓                           ↓
        ┌──────────────┐          ┌──────────────────┐
        │  RabbitMQ    │          │   PostgreSQL     │
        │  (AMQP)      │          │   (Databases)    │
        └──────────────┘          └──────────────────┘
```

---

### 2.2 Детальний розбір технологій по компонентах

#### **2.2.1 API Gateway**

| Компонент | Технологія | Версія | Обґрунтування |
|-----------|-----------|--------|---------------|
| Runtime | Node.js | 20 LTS | Асинхронний I/O, висока продуктивність для проксі-запитів |
| Framework | Express.js | 4.18 | Легковаговий, гнучкий routing, велика екосистема middleware |
| Language | TypeScript | 5.3 | Статична типізація, покращена підтримка IDE, меньше помилок |
| HTTP Client | Axios | 1.6 | Promise-based, interceptors, automatic transforms |
| Auth | jsonwebtoken | 9.0 | JWT токени, industry standard |
| Rate Limiting | express-rate-limit | 7.1 | Захист від DDoS, API throttling |
| CORS | cors | 2.8 | Cross-origin resource sharing |
| Validation | Joi | 17.11 | Schema validation для request/response |
| Logging | Winston | 3.11 | Structured logging, multiple transports |
| Circuit Breaker | opossum | 8.1 | Захист від каскадних відмов |

**Dockerfile для API Gateway:**
```dockerfile
FROM node:20-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
RUN npm run build

FROM node:20-alpine
WORKDIR /app
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
EXPOSE 3000
CMD ["node", "dist/index.js"]
```

---

#### **2.2.2 Users Service**

| Компонент | Технологія | Версія | Обґрунтування |
|-----------|-----------|--------|---------------|
| Runtime | Node.js | 20 LTS | Асинхронність, швидка розробка |
| Framework | Express.js | 4.18 | REST API, middleware підтримка |
| Language | TypeScript | 5.3 | Type safety для бізнес-логіки |
| ORM | Prisma | 5.7 | Type-safe database client, migrations, інтроспекція |
| Database | PostgreSQL | 16 | ACID, надійність, JSON support |
| Password Hashing | bcrypt | 5.1 | Cryptographically secure, salt rounds |
| JWT | jsonwebtoken | 9.0 | Токени доступу та refresh токени |
| Validation | Zod | 3.22 | TypeScript-first validation |
| Email | Nodemailer | 6.9 | Email sending через SMTP |
| Message Queue | amqplib | 0.10 | RabbitMQ client для Node.js |

**Environment Variables (.env):**
```env
# Database
DATABASE_URL="postgresql://user:password@postgres-users:5432/users_db?schema=public"

# JWT
JWT_ACCESS_SECRET="your-access-secret-key-256-bit"
JWT_REFRESH_SECRET="your-refresh-secret-key-256-bit"
JWT_ACCESS_EXPIRATION="15m"
JWT_REFRESH_EXPIRATION="7d"

# RabbitMQ
RABBITMQ_URL="amqp://guest:guest@rabbitmq:5672"

# Server
PORT=4001
NODE_ENV="production"
```

**Prisma Schema:**
```prisma
generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model User {
  id            Int       @id @default(autoincrement())
  email         String    @unique @db.VarChar(255)
  passwordHash  String    @map("password_hash") @db.VarChar(255)
  firstName     String    @map("first_name") @db.VarChar(100)
  lastName      String    @map("last_name") @db.VarChar(100)
  avatarUrl     String?   @map("avatar_url") @db.VarChar(500)
  isActive      Boolean   @default(true) @map("is_active")
  isVerified    Boolean   @default(false) @map("is_verified")
  createdAt     DateTime  @default(now()) @map("created_at")
  updatedAt     DateTime  @updatedAt @map("updated_at")

  roles         Role[]
  refreshTokens RefreshToken[]

  @@map("users")
}

model Role {
  id        Int      @id @default(autoincrement())
  userId    Int      @map("user_id")
  roleName  String   @map("role_name") @db.VarChar(50)
  createdAt DateTime @default(now()) @map("created_at")

  user User @relation(fields: [userId], references: [id], onDelete: Cascade)

  @@unique([userId, roleName])
  @@map("roles")
}

model RefreshToken {
  id        Int      @id @default(autoincrement())
  userId    Int      @map("user_id")
  token     String   @unique @db.VarChar(500)
  expiresAt DateTime @map("expires_at")
  createdAt DateTime @default(now()) @map("created_at")

  user User @relation(fields: [userId], references: [id], onDelete: Cascade)

  @@map("refresh_tokens")
}
```

---

#### **2.2.3 Projects Service**

| Компонент | Технологія | Версія | Обґрунтування |
|-----------|-----------|--------|---------------|
| Runtime | Node.js | 20 LTS | Consistency з іншими сервісами |
| Framework | Express.js | 4.18 | REST API |
| Language | TypeScript | 5.3 | Type safety |
| ORM | Prisma | 5.7 | Type-safe ORM |
| Database | PostgreSQL | 16 | Реляційні дані (проєкти, члени) |
| HTTP Client | Axios | 1.6 | Міжсервісні виклики (Users Service) |
| Validation | Zod | 3.22 | Request validation |
| Message Queue | amqplib | 0.10 | Event publishing |

---

#### **2.2.4 Tasks Service**

| Компонент | Технологія | Версія | Обґрунтування |
|-----------|-----------|--------|---------------|
| Runtime | Node.js | 20 LTS | Consistency з іншими сервісами |
| Framework | Express.js | 4.18 | REST API |
| Language | TypeScript | 5.3 | Type safety |
| ORM | Prisma | 5.7 | Підтримка складних зв'язків (tasks, comments, attachments) |
| Database | PostgreSQL | 16 | Реляційні дані, transactions |
| File Upload | Multer | 1.4 | Multipart/form-data parsing |
| File Storage | MinIO Client | 7.1 | S3-compatible object storage |
| HTTP Client | Axios | 1.6 | Виклики до Projects, Users Services |
| Message Queue | amqplib | 0.10 | Event publishing |

**File Upload Configuration:**
```typescript
import multer from 'multer';

const storage = multer.memoryStorage();

const upload = multer({
  storage,
  limits: {
    fileSize: 10 * 1024 * 1024, // 10 MB
  },
  fileFilter: (req, file, cb) => {
    const allowedMimeTypes = [
      'image/jpeg',
      'image/png',
      'image/gif',
      'application/pdf',
      'application/msword',
      'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    ];

    if (allowedMimeTypes.includes(file.mimetype)) {
      cb(null, true);
    } else {
      cb(new Error('Invalid file type'));
    }
  },
});

export default upload;
```

---

#### **2.2.5 Notifications Service**

| Компонент | Технологія | Версія | Обґрунтування |
|-----------|-----------|--------|---------------|
| Runtime | Node.js | 20 LTS | Асинхронна обробка подій |
| Framework | Express.js | 4.18 | REST API для управління нотифікаціями |
| Language | TypeScript | 5.3 | Type safety |
| ORM | Prisma | 5.7 | ORM для збереження нотифікацій |
| Database | PostgreSQL | 16 | Збереження історії нотифікацій |
| Email | Nodemailer | 6.9 | SMTP клієнт |
| Template Engine | Handlebars | 4.7 | Email templates |
| Message Queue | amqplib | 0.10 | RabbitMQ consumer |
| HTTP Client | Axios | 1.6 | Отримання даних користувачів |

**Email Template Example (Handlebars):**
```handlebars
<!DOCTYPE html>
<html>
<head>
  <style>
    body { font-family: Arial, sans-serif; }
    .container { max-width: 600px; margin: 0 auto; padding: 20px; }
    .header { background-color: #4CAF50; color: white; padding: 10px; }
    .content { padding: 20px; }
    .button { background-color: #4CAF50; color: white; padding: 10px 20px; text-decoration: none; }
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>TaskFlow Notification</h1>
    </div>
    <div class="content">
      <h2>New Task Assigned</h2>
      <p>Hello {{firstName}},</p>
      <p>You have been assigned to a new task: <strong>{{taskTitle}}</strong></p>
      <p>Project: {{projectName}}</p>
      <p>Priority: {{priority}}</p>
      <p>Deadline: {{deadline}}</p>
      <p>
        <a href="{{taskUrl}}" class="button">View Task</a>
      </p>
    </div>
  </div>
</body>
</html>
```

---

#### **2.2.6 Analytics Service**

| Компонент | Технологія | Версія | Обґрунтування |
|-----------|-----------|--------|---------------|
| Runtime | Python | 3.12 | Екосистема для data science, аналітики, візуалізації |
| Framework | FastAPI | 0.108 | Async, швидкий, auto-generated OpenAPI docs |
| ORM | SQLAlchemy | 2.0 | Python ORM, підтримка async |
| Database | PostgreSQL | 16 | Аналітичні дані, time-series |
| Message Queue | aio-pika | 9.3 | Async RabbitMQ client для Python |
| Data Analysis | Pandas | 2.1 | DataFrame operations, data manipulation |
| Visualization | Matplotlib | 3.8 | Графіки та charts |
| PDF Generation | ReportLab | 4.0 | PDF звіти |
| Excel Export | OpenPyXL | 3.1 | Excel файли |
| HTTP Client | httpx | 0.25 | Async HTTP client для міжсервісних викликів |

**FastAPI Application Structure:**
```python
from fastapi import FastAPI, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from typing import List
import pandas as pd

app = FastAPI(
    title="TaskFlow Analytics Service",
    version="1.0.0",
    description="Analytics and reporting service"
)

@app.get("/api/analytics/projects/{project_id}/burndown")
async def get_burndown_chart(
    project_id: int,
    start_date: str,
    end_date: str,
    db: AsyncSession = Depends(get_db)
):
    """Generate burndown chart data for a project"""
    # Fetch task events from database
    events = await fetch_task_events(db, project_id, start_date, end_date)

    # Use pandas for data manipulation
    df = pd.DataFrame(events)
    df['date'] = pd.to_datetime(df['timestamp']).dt.date

    # Calculate remaining work per day
    burndown_data = calculate_burndown(df)

    return {
        "project_id": project_id,
        "ideal_line": burndown_data["ideal"],
        "actual_line": burndown_data["actual"],
        "labels": burndown_data["dates"]
    }

@app.post("/api/analytics/reports/generate")
async def generate_report(
    report_request: ReportRequest,
    db: AsyncSession = Depends(get_db)
):
    """Generate PDF or Excel report"""
    data = await collect_report_data(db, report_request)

    if report_request.format == "pdf":
        file_buffer = generate_pdf_report(data)
    elif report_request.format == "excel":
        file_buffer = generate_excel_report(data)
    else:
        raise HTTPException(400, "Unsupported format")

    # Upload to MinIO
    file_url = await upload_to_storage(file_buffer, report_request)

    return {"report_url": file_url}
```

**Обґрунтування вибору Python для Analytics:**
- Pandas для ефективної обробки великих обсягів даних
- Matplotlib/Seaborn для візуалізації
- NumPy для математичних обчислень
- Велика екосистема ML/AI бібліотек (для майбутнього розширення)
- FastAPI забезпечує високу продуктивність (порівнянну з Node.js)

---

### 2.3 Інфраструктурні компоненти

#### **2.3.1 PostgreSQL**

**Версія:** 16 (Alpine Linux image для production)

**Конфігурація:**
- Окрема база даних для кожного сервісу (Database per Service pattern)
- Connection pooling через PgBouncer
- Replication: Primary-Replica для read scaling

**Databases:**
```
taskflow_users_db       (Users Service)
taskflow_projects_db    (Projects Service)
taskflow_tasks_db       (Tasks Service)
taskflow_notifications_db (Notifications Service)
taskflow_analytics_db   (Analytics Service)
```

**Docker Compose Configuration:**
```yaml
services:
  postgres-users:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: taskflow_users_db
      POSTGRES_USER: taskflow_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres-users-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U taskflow_user"]
      interval: 10s
      timeout: 5s
      retries: 5

  postgres-projects:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: taskflow_projects_db
      POSTGRES_USER: taskflow_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres-projects-data:/var/lib/postgresql/data

  # Similar configurations for other databases...

volumes:
  postgres-users-data:
  postgres-projects-data:
  postgres-tasks-data:
  postgres-notifications-data:
  postgres-analytics-data:
```

**Performance Tuning (postgresql.conf):**
```conf
# Memory Settings
shared_buffers = 256MB
effective_cache_size = 1GB
work_mem = 16MB
maintenance_work_mem = 64MB

# Connection Settings
max_connections = 100

# Write-Ahead Log
wal_buffers = 16MB
checkpoint_completion_target = 0.9

# Query Planner
random_page_cost = 1.1  # For SSD storage
```

---

#### **2.3.2 RabbitMQ**

**Версія:** 3.12-management (з Management UI)

**Plugins:**
- rabbitmq_management (Management UI)
- rabbitmq_prometheus (Metrics export)
- rabbitmq_shovel (Message forwarding)

**Configuration:**
```yaml
services:
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    environment:
      RABBITMQ_DEFAULT_USER: taskflow
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_DEFAULT_VHOST: /taskflow
    ports:
      - "5672:5672"    # AMQP
      - "15672:15672"  # Management UI
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
      - ./rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  rabbitmq-data:
```

**Exchange and Queue Setup:**
```javascript
// Initialize RabbitMQ topology
async function setupRabbitMQ(channel) {
  // Declare main topic exchange
  await channel.assertExchange('taskflow.events', 'topic', {
    durable: true
  });

  // Declare Dead Letter Exchange
  await channel.assertExchange('taskflow.dlx', 'topic', {
    durable: true
  });

  // Queues for Notifications Service
  await channel.assertQueue('notifications.user.registered', {
    durable: true,
    deadLetterExchange: 'taskflow.dlx',
    deadLetterRoutingKey: 'failed.notifications.user.registered'
  });

  await channel.bindQueue(
    'notifications.user.registered',
    'taskflow.events',
    'user.registered'
  );

  // Similar setup for other queues...
}
```

---

#### **2.3.3 MinIO (S3-Compatible Storage)**

**Версія:** RELEASE.2024-01-01 (latest stable)

**Використання:**
- Завантаження аватарів користувачів
- Прикріплення файлів до задач
- Зберігання згенерованих звітів (PDF, Excel)

**Configuration:**
```yaml
services:
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    ports:
      - "9000:9000"  # API
      - "9001:9001"  # Console
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

volumes:
  minio-data:
```

**Buckets:**
```
taskflow-avatars      (User profile pictures)
taskflow-attachments  (Task file attachments)
taskflow-reports      (Generated analytics reports)
```

**MinIO Client Usage (Tasks Service):**
```typescript
import { Client } from 'minio';

const minioClient = new Client({
  endPoint: process.env.MINIO_ENDPOINT || 'minio',
  port: parseInt(process.env.MINIO_PORT || '9000'),
  useSSL: process.env.MINIO_USE_SSL === 'true',
  accessKey: process.env.MINIO_ACCESS_KEY,
  secretKey: process.env.MINIO_SECRET_KEY,
});

// Upload file
async function uploadAttachment(file: Express.Multer.File, taskId: number) {
  const bucketName = 'taskflow-attachments';
  const fileName = `task-${taskId}/${Date.now()}-${file.originalname}`;

  await minioClient.putObject(
    bucketName,
    fileName,
    file.buffer,
    file.size,
    {
      'Content-Type': file.mimetype,
      'X-Task-ID': taskId.toString(),
    }
  );

  // Generate presigned URL (valid for 7 days)
  const url = await minioClient.presignedGetObject(bucketName, fileName, 7 * 24 * 60 * 60);

  return {
    fileName: file.originalname,
    fileSize: file.size,
    fileUrl: url,
    storagePath: fileName,
  };
}
```

---

#### **2.3.4 Redis (Caching and Session Storage)**

**Версія:** 7.2-alpine

**Використання:**
- Кешування часто запитуваних даних (user profiles, project info)
- Session storage для JWT refresh tokens
- Rate limiting counters
- Idempotency keys для event processing

**Configuration:**
```yaml
services:
  redis:
    image: redis:7.2-alpine
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  redis-data:
```

**Redis Client (Node.js):**
```typescript
import { createClient } from 'redis';

const redisClient = createClient({
  url: `redis://:${process.env.REDIS_PASSWORD}@redis:6379`,
});

await redisClient.connect();

// Caching example
async function getUserFromCache(userId: number) {
  const cacheKey = `user:${userId}`;
  const cached = await redisClient.get(cacheKey);

  if (cached) {
    return JSON.parse(cached);
  }

  // Fetch from database
  const user = await prisma.user.findUnique({ where: { id: userId } });

  // Cache for 1 hour
  await redisClient.setEx(cacheKey, 3600, JSON.stringify(user));

  return user;
}

// Idempotency example
async function processEventIdempotent(event: Event) {
  const idempotencyKey = `event:${event.type}:${event.id}`;
  const exists = await redisClient.get(idempotencyKey);

  if (exists) {
    console.log('Event already processed');
    return;
  }

  // Process event
  await handleEvent(event);

  // Mark as processed (TTL 24 hours)
  await redisClient.setEx(idempotencyKey, 86400, 'processed');
}
```

---

### 2.4 Моніторинг та Логування

#### **2.4.1 Prometheus + Grafana**

**Prometheus (Metrics Collection):**
```yaml
services:
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'

volumes:
  prometheus-data:
```

**prometheus.yml:**
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:3000']

  - job_name: 'users-service'
    static_configs:
      - targets: ['users-service:4001']

  - job_name: 'projects-service'
    static_configs:
      - targets: ['projects-service:4002']

  - job_name: 'tasks-service'
    static_configs:
      - targets: ['tasks-service:4003']

  - job_name: 'notifications-service'
    static_configs:
      - targets: ['notifications-service:4004']

  - job_name: 'analytics-service'
    static_configs:
      - targets: ['analytics-service:4005']

  - job_name: 'rabbitmq'
    static_configs:
      - targets: ['rabbitmq:15692']

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']
```

**Grafana (Visualization):**
```yaml
services:
  grafana:
    image: grafana/grafana:latest
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
      GF_INSTALL_PLUGINS: grafana-piechart-panel
    ports:
      - "3001:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources

volumes:
  grafana-data:
```

**Metrics Instrumentation (Express.js):**
```typescript
import promClient from 'prom-client';

// Create a Registry
const register = new promClient.Registry();

// Default metrics (CPU, memory, etc.)
promClient.collectDefaultMetrics({ register });

// Custom metrics
const httpRequestDuration = new promClient.Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'route', 'status_code'],
  buckets: [0.1, 0.5, 1, 2, 5],
});

register.registerMetric(httpRequestDuration);

// Middleware
app.use((req, res, next) => {
  const start = Date.now();

  res.on('finish', () => {
    const duration = (Date.now() - start) / 1000;
    httpRequestDuration
      .labels(req.method, req.route?.path || req.path, res.statusCode.toString())
      .observe(duration);
  });

  next();
});

// Metrics endpoint
app.get('/metrics', async (req, res) => {
  res.set('Content-Type', register.contentType);
  res.end(await register.metrics());
});
```

---

#### **2.4.2 ELK Stack (Logging)**

**Elasticsearch:**
```yaml
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data

volumes:
  elasticsearch-data:
```

**Logstash:**
```yaml
services:
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"  # Beats input
      - "9600:9600"  # Monitoring API
    depends_on:
      - elasticsearch
```

**logstash.conf:**
```conf
input {
  beats {
    port => 5044
  }
}

filter {
  json {
    source => "message"
  }

  mutate {
    add_field => { "index_date" => "%{+YYYY.MM.dd}" }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "taskflow-logs-%{index_date}"
  }

  stdout { codec => rubydebug }
}
```

**Kibana:**
```yaml
services:
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
```

**Structured Logging (Winston):**
```typescript
import winston from 'winston';

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json()
  ),
  defaultMeta: { service: 'users-service' },
  transports: [
    new winston.transports.File({ filename: 'error.log', level: 'error' }),
    new winston.transports.File({ filename: 'combined.log' }),
    new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.simple()
      ),
    }),
  ],
});

// Usage
logger.info('User registered', {
  userId: user.id,
  email: user.email,
  timestamp: new Date().toISOString(),
});

logger.error('Failed to send email', {
  error: error.message,
  stack: error.stack,
  userId: user.id,
});
```

---

### 2.5 Security Technologies

#### **2.5.1 HTTPS/TLS**

**Let's Encrypt (Production):**
- Автоматичні SSL сертифікати
- Auto-renewal через Certbot
- Nginx як reverse proxy

**Nginx Configuration:**
```nginx
server {
    listen 80;
    server_name taskflow.example.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name taskflow.example.com;

    ssl_certificate /etc/letsencrypt/live/taskflow.example.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/taskflow.example.com/privkey.pem;

    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers on;

    location /api/ {
        proxy_pass http://api-gateway:3000/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

---

#### **2.5.2 Secrets Management**

**Docker Secrets (Docker Swarm):**
```yaml
version: '3.8'

services:
  users-service:
    image: taskflow/users-service
    secrets:
      - db_password
      - jwt_secret
    environment:
      DATABASE_PASSWORD_FILE: /run/secrets/db_password
      JWT_SECRET_FILE: /run/secrets/jwt_secret

secrets:
  db_password:
    external: true
  jwt_secret:
    external: true
```

**Alternatives:**
- **HashiCorp Vault:** For production-grade secrets management
- **AWS Secrets Manager:** For AWS deployments
- **Azure Key Vault:** For Azure deployments

---

#### **2.5.3 Security Headers**

**Helmet.js (Express):**
```typescript
import helmet from 'helmet';

app.use(helmet());

// Custom configuration
app.use(helmet({
  contentSecurityPolicy: {
    directives: {
      defaultSrc: ["'self'"],
      styleSrc: ["'self'", "'unsafe-inline'"],
      scriptSrc: ["'self'"],
      imgSrc: ["'self'", "data:", "https://storage.taskflow.com"],
    },
  },
  hsts: {
    maxAge: 31536000,
    includeSubDomains: true,
    preload: true,
  },
}));
```

---

### 2.6 DevOps та CI/CD

#### **2.6.1 Containerization**

**Multi-stage Dockerfile (Example):**
```dockerfile
# Stage 1: Build
FROM node:20-alpine AS builder

WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY tsconfig.json ./
COPY src ./src
RUN npm run build

# Stage 2: Production
FROM node:20-alpine

WORKDIR /app

# Create non-root user
RUN addgroup -g 1001 nodejs && adduser -u 1001 -G nodejs -s /bin/sh -D nodejs

# Copy built files
COPY --from=builder --chown=nodejs:nodejs /app/dist ./dist
COPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --chown=nodejs:nodejs package.json ./

USER nodejs

EXPOSE 4001

HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node -e "require('http').get('http://localhost:4001/health', (r) => { process.exit(r.statusCode === 200 ? 0 : 1); });"

CMD ["node", "dist/index.js"]
```

---

#### **2.6.2 Docker Compose (Development)**

**docker-compose.yml:**
```yaml
version: '3.8'

services:
  # Infrastructure
  postgres-users:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: taskflow_users_db
      POSTGRES_USER: taskflow_user
      POSTGRES_PASSWORD: dev_password
    volumes:
      - postgres-users-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    environment:
      RABBITMQ_DEFAULT_USER: taskflow
      RABBITMQ_DEFAULT_PASS: dev_password
    ports:
      - "5672:5672"
      - "15672:15672"

  redis:
    image: redis:7.2-alpine
    command: redis-server --requirepass dev_password
    ports:
      - "6379:6379"

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"

  # Microservices
  api-gateway:
    build:
      context: ./services/api-gateway
      dockerfile: Dockerfile
    environment:
      PORT: 3000
      NODE_ENV: development
    ports:
      - "3000:3000"
    depends_on:
      - users-service
      - projects-service
      - tasks-service

  users-service:
    build: ./services/users-service
    environment:
      DATABASE_URL: postgresql://taskflow_user:dev_password@postgres-users:5432/taskflow_users_db
      RABBITMQ_URL: amqp://taskflow:dev_password@rabbitmq:5672
      REDIS_URL: redis://:dev_password@redis:6379
      PORT: 4001
    ports:
      - "4001:4001"
    depends_on:
      - postgres-users
      - rabbitmq
      - redis

  # ... other services

volumes:
  postgres-users-data:
  rabbitmq-data:
  redis-data:
  minio-data:
```

---

#### **2.6.3 GitHub Actions CI/CD**

**.github/workflows/ci.yml:**
```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [api-gateway, users-service, projects-service, tasks-service]

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: services/${{ matrix.service }}/package-lock.json

      - name: Install dependencies
        working-directory: services/${{ matrix.service }}
        run: npm ci

      - name: Run linter
        working-directory: services/${{ matrix.service }}
        run: npm run lint

      - name: Run tests
        working-directory: services/${{ matrix.service }}
        run: npm test

      - name: Build
        working-directory: services/${{ matrix.service }}
        run: npm run build

  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
      - uses: actions/checkout@v4

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build and push Docker images
        run: |
          docker build -t taskflow/api-gateway:latest ./services/api-gateway
          docker push taskflow/api-gateway:latest

          docker build -t taskflow/users-service:latest ./services/users-service
          docker push taskflow/users-service:latest

          # ... other services

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
      - name: Deploy to production
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ secrets.PRODUCTION_HOST }}
          username: ${{ secrets.PRODUCTION_USER }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            cd /opt/taskflow
            docker-compose pull
            docker-compose up -d
            docker system prune -af
```

---

#### **2.6.4 Kubernetes (Production Orchestration)**

**users-service-deployment.yaml:**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: users-service
  namespace: taskflow
spec:
  replicas: 3
  selector:
    matchLabels:
      app: users-service
  template:
    metadata:
      labels:
        app: users-service
    spec:
      containers:
      - name: users-service
        image: taskflow/users-service:latest
        ports:
        - containerPort: 4001
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: users-service-secrets
              key: database-url
        - name: JWT_ACCESS_SECRET
          valueFrom:
            secretKeyRef:
              name: users-service-secrets
              key: jwt-access-secret
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 4001
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 4001
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: users-service
  namespace: taskflow
spec:
  selector:
    app: users-service
  ports:
  - protocol: TCP
    port: 4001
    targetPort: 4001
  type: ClusterIP

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: users-service-hpa
  namespace: taskflow
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: users-service
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

---

## 3. Діаграма розгортання (Deployment Diagram)

Створено окремий файл: `ЛР4_Deployment_Diagram.puml`

---

## 4. Висновки

У ході виконання лабораторної роботи №4 було визначено та обґрунтовано технологічний стек для системи TaskFlow:

### 4.1 Основні технологічні рішення

1. **Backend:** Node.js 20 + Express + TypeScript для більшості сервісів
   - Асинхронний I/O для високої пропускної здатності
   - TypeScript для type safety та кращої підтримки IDE
   - Єдина мова для всіх сервісів (крім Analytics)

2. **Analytics Service:** Python 3.12 + FastAPI
   - Pandas/NumPy для ефективної обробки даних
   - Matplotlib для візуалізації
   - Велика екосистема data science бібліотек

3. **Databases:** PostgreSQL 16 (Database per Service)
   - ACID compliance для надійності
   - JSON support для гнучкості
   - Proven technology для production

4. **Message Broker:** RabbitMQ 3.12
   - Гнучкий routing через topic exchanges
   - Management UI для моніторингу
   - Dead Letter Queue для fault tolerance

5. **Caching:** Redis 7.2
   - In-memory storage для швидкого доступу
   - Idempotency keys
   - Rate limiting counters

6. **File Storage:** MinIO (S3-compatible)
   - Self-hosted alternative до AWS S3
   - Presigned URLs для безпечного доступу
   - Scalable object storage

7. **Monitoring:** Prometheus + Grafana
   - Metrics collection та alerting
   - Real-time dashboards
   - Industry standard tools

8. **Logging:** ELK Stack (Elasticsearch, Logstash, Kibana)
   - Centralized logging
   - Full-text search
   - Log analysis та visualization

9. **Orchestration:** Kubernetes
   - Auto-scaling (HPA)
   - Self-healing
   - Rolling updates та rollbacks

### 4.2 Переваги обраного стеку

- **Консистентність:** Node.js для більшості сервісів
- **Type Safety:** TypeScript у всіх Node.js сервісах
- **Продуктивність:** FastAPI (Python) майже так само швидкий як Node.js
- **Екосистема:** Велика кількість бібліотек та інструментів
- **Community Support:** Активні спільноти для всіх технологій
- **Production-Ready:** Всі технології proven у production середовищах

### 4.3 Масштабованість

- Horizontal scaling через Kubernetes HPA
- Database connection pooling (PgBouncer)
- Redis caching для зменшення навантаження на БД
- RabbitMQ для асинхронної обробки
- MinIO distributed mode для file storage scaling

---

## 5. Відповіді на контрольні питання

### Питання 1: Які фактори впливають на вибір технологічного стеку?

**Відповідь:**

При виборі технологічного стеку необхідно враховувати наступні фактори:

1. **Функціональні вимоги:**
   - Тип додатку (web, mobile, desktop, IoT)
   - Необхідні функції (real-time, batch processing, ML/AI)
   - Інтеграції з іншими системами

2. **Нефункціональні вимоги:**
   - **Продуктивність:** Latency, throughput, resource utilization
   - **Масштабованість:** Horizontal vs vertical scaling
   - **Надійність:** Uptime requirements, fault tolerance
   - **Безпека:** Authentication, encryption, compliance

3. **Технічні фактори:**
   - **Екосистема:** Наявність бібліотек, фреймворків, інструментів
   - **Community:** Розмір спільноти, активність розробки
   - **Документація:** Якість та повнота документації
   - **Backward compatibility:** Стабільність API

4. **Команда:**
   - **Експертиза:** Знання та досвід команди
   - **Навчальна крива:** Час на вивчення нових технологій
   - **Hiring:** Доступність розробників на ринку

5. **Бізнес-фактори:**
   - **Time to market:** Швидкість розробки MVP
   - **Вартість:** Ліцензування, hosting, підтримка
   - **Vendor lock-in:** Залежність від постачальника
   - **Довгострокова підтримка:** LTS versions, roadmap

6. **Operational factors:**
   - **DevOps:** CI/CD, monitoring, logging
   - **Deployment:** Containerization, orchestration
   - **Maintenance:** Updates, patches, migrations

**Приклад для TaskFlow:**
- Вибрано Node.js через асинхронність (good для I/O-intensive operations)
- Python для Analytics через pandas/matplotlib екосистему
- PostgreSQL через ACID та proven reliability
- Kubernetes для production orchestration та auto-scaling

---

### Питання 2: Чому обрано PostgreSQL замість NoSQL (MongoDB)?

**Відповідь:**

**Обґрунтування вибору PostgreSQL:**

1. **Реляційна структура даних:**
   - Проєкти, задачі, користувачі мають чіткі зв'язки (foreign keys)
   - One-to-many, many-to-many relationships (projects-members, tasks-comments)
   - Потрібна referential integrity (CASCADE DELETE)

2. **ACID Transactions:**
   - Критично для фінансових операцій (якщо буде billing)
   - Atomic operations (створення проєкту + додавання членів = одна транзакція)
   - Consistency guarantees

3. **Complex Queries:**
   - JOIN операції для аналітики (tasks JOIN projects JOIN users)
   - Aggregations (COUNT, SUM, AVG для звітів)
   - Window functions для burndown charts

4. **Data Integrity:**
   - Foreign key constraints
   - UNIQUE constraints (email)
   - CHECK constraints (priority in ['low', 'medium', 'high'])

5. **JSON Support:**
   - PostgreSQL має JSONB type для гнучких полів
   - Indexes на JSON полях
   - Best of both worlds (relational + document)

**Коли MongoDB був би кращим:**
- Якщо схема даних часто змінюється (flexible schema)
- Якщо потрібен horizontal sharding out-of-the-box
- Якщо переважно document-based операції без JOIN'ів
- Якщо eventual consistency прийнятна

**Висновок для TaskFlow:**
PostgreSQL обрано через:
- Складні зв'язки між entities
- Потреба в транзакціях
- SQL expertise в команді
- Proven reliability для production

---

### Питання 3: Які переваги дає використання Docker та Kubernetes?

**Відповідь:**

**Docker (Containerization):**

**Переваги:**

1. **Consistency (Консистентність):**
   - "Works on my machine" problem вирішена
   - Однакове середовище: dev, staging, production
   - Всі залежності упаковані в image

2. **Isolation (Ізоляція):**
   - Кожен сервіс в окремому контейнері
   - Не конфліктують версії (Node.js 18 vs Node.js 20)
   - Resource limits (CPU, memory)

3. **Portability (Переносимість):**
   - Run anywhere: local, cloud, on-premise
   - Cloud-agnostic (AWS, Azure, GCP)
   - Easy migration between environments

4. **Efficiency (Ефективність):**
   - Lightweight (share OS kernel)
   - Fast startup (seconds vs minutes для VM)
   - Більше containers на одному host

5. **Version Control:**
   - Image tags для versioning (v1.0.0, v1.1.0)
   - Rollback до попередньої версії
   - Immutable infrastructure

**Kubernetes (Orchestration):**

**Переваги:**

1. **Auto-Scaling:**
   - Horizontal Pod Autoscaler (HPA) based on CPU/memory
   - Scale up при високому навантаженні
   - Scale down для економії ресурсів

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: users-service-hpa
spec:
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        averageUtilization: 70
```

2. **Self-Healing:**
   - Automatic restart failed containers
   - Replace unresponsive pods
   - Health checks (liveness, readiness probes)

3. **Load Balancing:**
   - Automatic traffic distribution
   - Service discovery
   - Internal DNS

4. **Rolling Updates:**
   - Zero-downtime deployments
   - Gradual rollout (10% → 50% → 100%)
   - Automatic rollback при помилках

```yaml
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
```

5. **Service Discovery:**
   - Automatic DNS для services
   - Environment variables injection
   - ConfigMaps та Secrets management

6. **Resource Management:**
   - Resource requests та limits
   - Quality of Service (QoS) classes
   - Node affinity/anti-affinity

**Приклад для TaskFlow:**

**Without Kubernetes:**
- Manual scaling: SSH до серверів, run docker-compose up --scale
- Manual recovery: Моніторити crashes, manually restart
- Manual updates: Stop services, pull new images, restart

**With Kubernetes:**
- Auto-scaling based on metrics
- Automatic recovery при crashes
- Rolling updates з одної команди: `kubectl apply -f deployment.yaml`

---

### Питання 4: Що таке CI/CD і які інструменти використовуються?

**Відповідь:**

**CI/CD (Continuous Integration / Continuous Deployment):**

**Continuous Integration (CI):**
- Автоматичне тестування коду при кожному commit
- Автоматична збірка (build) додатку
- Linting та code quality checks
- Security scanning

**Continuous Deployment (CD):**
- Автоматичне розгортання на staging/production
- Automated testing на staging
- Automatic rollback при помилках

**GitHub Actions Pipeline для TaskFlow:**

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  # 1. Code Quality
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
      - run: npm ci
      - run: npm run lint      # ESLint
      - run: npm run format    # Prettier check

  # 2. Security Scanning
  security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: snyk/actions/node@master  # Vulnerability scanning
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}

  # 3. Unit Tests
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
      - run: npm ci
      - run: npm test          # Jest unit tests
      - run: npm run test:coverage

  # 4. Build Docker Images
  build:
    needs: [lint, security, test]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: docker/login-action@v3
      - uses: docker/build-push-action@v5
        with:
          push: true
          tags: taskflow/users-service:${{ github.sha }}

  # 5. Deploy to Staging
  deploy-staging:
    needs: build
    if: github.ref == 'refs/heads/develop'
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to Staging
        run: |
          kubectl set image deployment/users-service \
            users-service=taskflow/users-service:${{ github.sha }} \
            --namespace=staging

  # 6. Integration Tests on Staging
  integration-tests:
    needs: deploy-staging
    runs-on: ubuntu-latest
    steps:
      - run: npm run test:integration

  # 7. Deploy to Production
  deploy-production:
    needs: integration-tests
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    environment:
      name: production
      url: https://taskflow.example.com
    steps:
      - name: Deploy to Production
        run: |
          kubectl set image deployment/users-service \
            users-service=taskflow/users-service:${{ github.sha }} \
            --namespace=production
```

**Інструменти CI/CD:**

| Інструмент | Призначення | Переваги |
|-----------|-------------|----------|
| **GitHub Actions** | CI/CD platform | Інтеграція з GitHub, безкоштовно для public repos |
| **GitLab CI** | CI/CD platform | Built-in в GitLab, потужні pipelines |
| **Jenkins** | CI/CD server | Open-source, велика кількість plugins |
| **CircleCI** | CI/CD platform | Швидкі builds, Docker-first |
| **Travis CI** | CI/CD platform | Простота налаштування |
| **ArgoCD** | GitOps CD | Kubernetes-native, declarative deployments |

**Best Practices:**

1. **Automated Testing:**
   - Unit tests (80%+ coverage)
   - Integration tests
   - E2E tests на staging

2. **Environment Parity:**
   - Dev, staging, production ідентичні
   - Infrastructure as Code (Terraform, CloudFormation)

3. **Fail Fast:**
   - Stop pipeline on first failure
   - Quick feedback loop

4. **Security:**
   - Scan dependencies (Snyk, Dependabot)
   - Container scanning (Trivy, Clair)
   - Secrets management (GitHub Secrets, Vault)

5. **Monitoring:**
   - Monitor deployments
   - Automatic rollback on errors
   - Alerts на Slack/Email

---

### Питання 5: Як забезпечити high availability розподіленої системи?

**Відповідь:**

**High Availability (HA)** означає, що система доступна 99.9%+ часу (максимум 8.76 годин downtime на рік).

**Стратегії для TaskFlow:**

**1. Redundancy (Надлишковість):**

**Application Layer:**
- Мінімум 3 replicas кожного сервісу в Kubernetes
- Load balancing між repliсами

```yaml
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1  # Мінімум 2 pods завжди running
```

**Database Layer:**
- PostgreSQL Primary-Replica replication
- Automatic failover (Patroni, Stolon)
- Read replicas для розподілення read навантаження

**2. Health Checks:**

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 4001
  initialDelaySeconds: 30
  periodSeconds: 10
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /ready
    port: 4001
  initialDelaySeconds: 5
  periodSeconds: 5
```

**3. Circuit Breaker:**
- Захист від cascading failures
- Automatic fallback при недоступності downstream service

**4. Message Queue Durability:**
- Durable queues та exchanges в RabbitMQ
- Message persistence на диск
- Cluster mode (3+ nodes)

**5. Database Backups:**
- Automated daily backups
- Point-in-time recovery (PITR)
- Replication to multiple availability zones

**6. Multi-Zone Deployment:**

```yaml
apiVersion: v1
kind: Pod
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - users-service
        topologyKey: topology.kubernetes.io/zone
```

**7. Monitoring and Alerting:**
- Prometheus metrics
- Grafana dashboards
- PagerDuty/Opsgenie для alerts

**8. Graceful Degradation:**
- Критичні функції працюють навіть при падінні некритичних
- Example: Users можуть працювати з tasks навіть якщо Analytics Service down

**Розрахунок Availability:**

```
Single instance availability: 99% (3.65 days downtime/year)

With 3 replicas:
Availability = 1 - (1 - 0.99)^3 = 1 - 0.000001 = 99.9999% (31.5 seconds downtime/year)
```

**Target SLA для TaskFlow:**
- 99.9% availability (8.76 hours downtime/year)
- Recovery Time Objective (RTO): < 5 minutes
- Recovery Point Objective (RPO): < 15 minutes (max data loss)

---

## 6. Використані матеріали

1. **Офіційна документація:**
   - Docker Documentation
   - Kubernetes Documentation
   - PostgreSQL Documentation
   - RabbitMQ Documentation
   - Node.js Documentation
   - Python/FastAPI Documentation

2. **Книги:**
   - "Docker Deep Dive" - Nigel Poulton
   - "Kubernetes in Action" - Marko Lukša
   - "Designing Data-Intensive Applications" - Martin Kleppmann

3. **Online Resources:**
   - The Twelve-Factor App (https://12factor.net)
   - Awesome Docker (GitHub)
   - Kubernetes Best Practices

---

**Підпис студента:** _______________
**Дата:** 18.12.2025
